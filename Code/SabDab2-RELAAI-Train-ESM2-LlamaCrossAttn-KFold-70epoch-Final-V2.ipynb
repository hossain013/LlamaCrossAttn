{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efac3282-17b1-45e0-ae4a-1034adcf63c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-01-04 06:43:20.113967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767530600.306717   62293 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767530600.376601   62293 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767530600.727366   62293 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767530600.727405   62293 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767530600.727408   62293 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767530600.727411   62293 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] ='tensorflow'\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from keras import layers, Model, Input\n",
    "from keras_hub.src.models.llama.llama_decoder import LlamaTransformerDecoder\n",
    "from keras_hub.src.models.llama.llama_layernorm import LlamaLayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18607b-2f76-46ab-b443-465dfee810cc",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4023231-5c03-4f31-aa67-504f145b1cab",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1692/1692 [00:37<00:00, 44.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "file_path = \"./data/SabDab-RELAAI/SabDab_RELAAI_esmt36_Full.h5\"\n",
    "load_seq = {}\n",
    "\n",
    "with h5py.File(file_path, \"r\") as hf:\n",
    "    for seq in tqdm(hf.keys()):\n",
    "        load_seq[seq] = hf[seq][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0acd2b6-b8a6-4d9e-96a3-72aa1c228a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab_seq</th>\n",
       "      <th>ag_seq</th>\n",
       "      <th>Hseq</th>\n",
       "      <th>Lseq</th>\n",
       "      <th>Ab_cluster</th>\n",
       "      <th>Ag_cluster</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYTFTSYWLHWVRQAPGKGLE...</td>\n",
       "      <td>MKYQLPNFTAETPIQNVILHEHHIFLGATNYIYVLNEEDLQKVAEY...</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYTFTSYWLHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCKSSQSLLYTSSQKNYLAWYQQKP...</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QVQLVESGGGVVQPGRSLRLSCAASGFTFSSYGMHWVRQAPGKGLE...</td>\n",
       "      <td>VMDFLFEKWKLYGDQCHHNLSLLPPPTELVCNRTFDKYSCWPDTPA...</td>\n",
       "      <td>QVQLVESGGGVVQPGRSLRLSCAASGFTFSSYGMHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>66</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QVQLQQSGAELARPGASVKLSCKASGYTFTDYYINWMKQRTGQGLE...</td>\n",
       "      <td>REHWATRLGLILAMAGNAVGLGNFLRFPVQAAENGGGAFMIPYIIA...</td>\n",
       "      <td>QVQLQQSGAELARPGASVKLSCKASGYTFTDYYINWMKQRTGQGLE...</td>\n",
       "      <td>DIVLTQSPASLAVSLGQRATISCKASQSVDYDGDSYMNWYQQKPGQ...</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QVQLQQPGAELVRPGASVKLSCKASGYTLTTYWMNWFKQRPDQGLE...</td>\n",
       "      <td>STATLCLGHHAVPNGTLVKTITDDQIEVTNATELVQSSSTGKICNN...</td>\n",
       "      <td>QVQLQQPGAELVRPGASVKLSCKASGYTLTTYWMNWFKQRPDQGLE...</td>\n",
       "      <td>DVVMTQTPLSLPVSLGDQASISCRSSQTLVHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QVQLKESGPGLVAPSQSLSITCTVSGFLLISNGVHWVRQPPGKGLE...</td>\n",
       "      <td>STATLCLGHHAVPNGTLVKTITDDQIEVTNATELVQSSSTGKICNN...</td>\n",
       "      <td>QVQLKESGPGLVAPSQSLSITCTVSGFLLISNGVHWVRQPPGKGLE...</td>\n",
       "      <td>QAVVTQESALTTSPGETVTLTCRSSTGAVTTSNYANWVQEKPDHLF...</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ab_seq  \\\n",
       "0  EVQLVESGGGLVQPGGSLRLSCAASGYTFTSYWLHWVRQAPGKGLE...   \n",
       "1  QVQLVESGGGVVQPGRSLRLSCAASGFTFSSYGMHWVRQAPGKGLE...   \n",
       "2  QVQLQQSGAELARPGASVKLSCKASGYTFTDYYINWMKQRTGQGLE...   \n",
       "3  QVQLQQPGAELVRPGASVKLSCKASGYTLTTYWMNWFKQRPDQGLE...   \n",
       "4  QVQLKESGPGLVAPSQSLSITCTVSGFLLISNGVHWVRQPPGKGLE...   \n",
       "\n",
       "                                              ag_seq  \\\n",
       "0  MKYQLPNFTAETPIQNVILHEHHIFLGATNYIYVLNEEDLQKVAEY...   \n",
       "1  VMDFLFEKWKLYGDQCHHNLSLLPPPTELVCNRTFDKYSCWPDTPA...   \n",
       "2  REHWATRLGLILAMAGNAVGLGNFLRFPVQAAENGGGAFMIPYIIA...   \n",
       "3  STATLCLGHHAVPNGTLVKTITDDQIEVTNATELVQSSSTGKICNN...   \n",
       "4  STATLCLGHHAVPNGTLVKTITDDQIEVTNATELVQSSSTGKICNN...   \n",
       "\n",
       "                                                Hseq  \\\n",
       "0  EVQLVESGGGLVQPGGSLRLSCAASGYTFTSYWLHWVRQAPGKGLE...   \n",
       "1  QVQLVESGGGVVQPGRSLRLSCAASGFTFSSYGMHWVRQAPGKGLE...   \n",
       "2  QVQLQQSGAELARPGASVKLSCKASGYTFTDYYINWMKQRTGQGLE...   \n",
       "3  QVQLQQPGAELVRPGASVKLSCKASGYTLTTYWMNWFKQRPDQGLE...   \n",
       "4  QVQLKESGPGLVAPSQSLSITCTVSGFLLISNGVHWVRQPPGKGLE...   \n",
       "\n",
       "                                                Lseq  Ab_cluster  Ag_cluster  \\\n",
       "0  DIQMTQSPSSLSASVGDRVTITCKSSQSLLYTSSQKNYLAWYQQKP...         147           0   \n",
       "1  DIQMTQSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...          66         392   \n",
       "2  DIVLTQSPASLAVSLGQRATISCKASQSVDYDGDSYMNWYQQKPGQ...         148           1   \n",
       "3  DVVMTQTPLSLPVSLGDQASISCRSSQTLVHSNGNTYLHWYLQKPG...          95           2   \n",
       "4  QAVVTQESALTTSPGETVTLTCRSSTGAVTTSNYANWVQEKPDHLF...         195           2   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/SabDab-RELAAI/AbAg_record_level_balanced_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fd7749-31ef-453b-a7c7-97eadf52c7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    3782\n",
       "0    3782\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cae6a53-8e6e-4f82-96fb-970c6bf9c32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "def process_sequence_tf(x_emb, max_len=512, pad_value=0.0):\n",
    "    seq_len = x_emb.shape[0]\n",
    "    \n",
    "    if seq_len > max_len:\n",
    "        # truncate\n",
    "        x_emb = tf.convert_to_tensor(x_emb[:max_len])\n",
    "        mask = tf.ones([max_len], dtype=tf.float32)\n",
    "    else:\n",
    "        # pad\n",
    "        pad_len = max_len - seq_len\n",
    "        paddings = [[0, pad_len], [0, 0]]\n",
    "        x_emb = tf.pad(x_emb, paddings, constant_values=pad_value)\n",
    "        mask = tf.pad(tf.ones([seq_len], dtype=tf.float32), [[0, pad_len]], constant_values=0.0)\n",
    "    \n",
    "    return x_emb, mask\n",
    "\n",
    "# -----------------------------\n",
    "# Keras Sequence Loader\n",
    "# -----------------------------\n",
    "class DataSequenceLoader(Sequence):\n",
    "    def __init__(self, df, batch_size=32, shuffle=True, max_len=512, pad_value=0.0):\n",
    "        self.x1_emb = df[\"ab_seq\"].values\n",
    "        self.x2_emb = df[\"ag_seq\"].values\n",
    "        self.labels = df[\"label\"].values\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.max_len = max_len\n",
    "        self.pad_value = pad_value\n",
    "        self.indices = np.arange(len(df))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "\n",
    "        x1_list, x2_list, m1_list, m2_list = [], [], [], []\n",
    "        labels_list = []\n",
    "\n",
    "        for i in batch_idx:\n",
    "            emb1 = load_seq[self.x1_emb[i]].reshape(-1, 2560)\n",
    "            emb2 = load_seq[self.x2_emb[i]].reshape(-1, 2560)\n",
    "\n",
    "            # ---- process embeddings + mask ----\n",
    "            x1_pad, mask1 = process_sequence_tf(emb1, max_len=self.max_len, pad_value=self.pad_value)\n",
    "            x2_pad, mask2 = process_sequence_tf(emb2, max_len=self.max_len, pad_value=self.pad_value)\n",
    "\n",
    "            x1_list.append(x1_pad.numpy())\n",
    "            x2_list.append(x2_pad.numpy())\n",
    "            m1_list.append(mask1.numpy())\n",
    "            m2_list.append(mask2.numpy())\n",
    "            labels_list.append(self.labels[i])\n",
    "\n",
    "        # Convert lists to arrays for batch\n",
    "        x1_batch = np.stack(x1_list, axis=0)\n",
    "        x2_batch = np.stack(x2_list, axis=0)\n",
    "        m1_batch = np.stack(m1_list, axis=0)\n",
    "        m2_batch = np.stack(m2_list, axis=0)\n",
    "        labels_batch = np.array(labels_list)\n",
    "\n",
    "        return (x1_batch, x2_batch, m1_batch, m2_batch), labels_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a643463-b27a-44ba-b50f-6ae7081dd5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loader  = DataSequenceLoader(df,batch_size=4,shuffle =True)\n",
    "# for x in loader:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e053595-ecc9-4960-8d23-7f77235440b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Hybrid Pooling Layer (Max + Avg)\n",
    "# -------------------------------------------------------------------\n",
    "class HybridPooling(layers.Layer):\n",
    "    def call(self, x):\n",
    "        max_pooled = keras.ops.max(x, axis=1)\n",
    "        avg_pooled = keras.ops.mean(x, axis=1)\n",
    "        return keras.ops.concatenate([max_pooled, avg_pooled], axis=-1)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Conv Block (Conv1D → ReLU → Dropout → MaxPool)\n",
    "# -------------------------------------------------------------------\n",
    "def conv_block(x, filters =  100, kernel_sz =20, stride =10, dropout = 0.5):\n",
    "    x = layers.Conv1D(filters, kernel_sz, strides=stride)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=1, padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Cross-attention (Query=X1, Key=X2, Value=X2)\n",
    "# -------------------------------------------------------------------\n",
    "def cross_attention_block(query, key, value, mask, num_heads =4, key_dim =32):\n",
    "    attn = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, \n",
    "        key_dim=key_dim,\n",
    "        dropout=0.0,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        use_bias=True,\n",
    "        # flash_attention=None,  # if GPU supports\n",
    "    )(query, key, value, key_mask=mask, value_mask=mask)\n",
    "    return attn\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# LLaMA Self-Attention Block\n",
    "# -------------------------------------------------------------------\n",
    "def llama_self_attention(x, mask, hidden_dim =100, num_heads = 4):\n",
    "    # single LLaMA decoder layer\n",
    "    llama = LlamaTransformerDecoder(\n",
    "        intermediate_dim=hidden_dim * 4,\n",
    "        # num_heads=num_heads,\n",
    "        num_query_heads=8,\n",
    "        num_key_value_heads=2,\n",
    "        dropout=0.0,\n",
    "        layer_norm_epsilon=1e-5,\n",
    "        activation=\"silu\"\n",
    "    )\n",
    "    return llama(x, decoder_padding_mask=mask)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Functional API Model (PyTorch → Keras Conversion)\n",
    "# -------------------------------------------------------------------\n",
    "def build_model(\n",
    "    input_dim=2560,\n",
    "    conv_out=100,\n",
    "    kernel_sz=20,\n",
    "    stride=10,\n",
    "    heads=4,\n",
    "    d_dim=32,\n",
    "    drop_pool=0.5,\n",
    "    drop_linear=0.3\n",
    "):\n",
    "    # Inputs\n",
    "    inp1 = Input((None, 2560))\n",
    "    inp2 = Input((None, 2560))\n",
    "    mask1 = Input((None, ))\n",
    "    mask2 = Input((None, ))\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 1) Convolutional features\n",
    "    # ---------------------------------------------------\n",
    "    # p1 = conv_block(inp1, conv_out, kernel_sz, stride, drop_pool)\n",
    "    # p2 = conv_block(inp2, conv_out, kernel_sz, stride, drop_pool)\n",
    "    x_dim = 384\n",
    "    p1 = layers.Dense(x_dim, use_bias=False,name='stem1')(inp1)\n",
    "    p1 = layers.BatchNormalization(momentum=0.95,name='bn1')(p1)\n",
    "    \n",
    "    p2 = layers.Dense(x_dim, use_bias=False,name='stem2')(inp2)\n",
    "    p2 = layers.BatchNormalization(momentum=0.95,name='bn2')(p2)\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 2) Self Attention using LLaMA blocks\n",
    "    # ---------------------------------------------------\n",
    "    s1 = llama_self_attention(p1, mask1, conv_out, heads)\n",
    "    s2 = llama_self_attention(p2, mask2, conv_out, heads)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 3) Cross Attention (1→2 and 2→1)\n",
    "    # ---------------------------------------------------\n",
    "    c1 = cross_attention_block(p1, p2, p2, mask2, heads, d_dim)\n",
    "    c2 = cross_attention_block(p2, p1, p1, mask1, heads, d_dim)\n",
    "\n",
    "    # Add residual (same as PyTorch + skip)\n",
    "    sc1 = layers.Add()([s1, c1])\n",
    "    sc2 = layers.Add()([s2, c2])\n",
    "\n",
    "    sc1 = layers.Dropout(drop_pool)(sc1)\n",
    "    sc2 = layers.Dropout(drop_pool)(sc2)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 4) Hybrid Pooling (max + mean)\n",
    "    # ---------------------------------------------------\n",
    "    h1 = HybridPooling()(sc1)\n",
    "    h2 = HybridPooling()(sc2)\n",
    "\n",
    "    merged = layers.Concatenate()([h1, h2])\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 5) MLP Head\n",
    "    # ---------------------------------------------------\n",
    "    x = layers.Dense(256, activation=\"relu\")(merged)\n",
    "    x = layers.Dropout(drop_linear)(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(drop_linear)(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs=[inp1, inp2, mask1, mask2], outputs=out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e164b962-a553-4248-b9df-25cca21c9b07",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix\n",
    ")\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea20fa3-a074-4f34-84db-78915862948d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights/SabDab2-RLEAAI-ESM_T36-20260104-064451'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# DEFAULT CONFIG (Logged Automatically to W&B)\n",
    "# =========================================================\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"batch_size\": 64,\n",
    "    \"n_splits\": 5,\n",
    "    \"epochs\": 70,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"architecture\": \"ESM_T36\",\n",
    "    \"dataset\": \"SabDab2\",\n",
    "    \"task\": \"Prot-Prot Classification\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_len\":512,\n",
    "}\n",
    "\n",
    "PROJECT_NAME = f\"{CONFIG['dataset']}-RLEAAI-{CONFIG['architecture']}-{TIMESTAMP}\"\n",
    "OUT_PATH = os.path.join(\"weights\",PROJECT_NAME)\n",
    "os.makedirs(os.path.join(OUT_PATH, \"logs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_PATH, \"weights\"), exist_ok=True)\n",
    "OUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a661e-7041-4b6c-b2ff-aee678d041c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      " Fold 1 / 5\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhossainstudy7\u001b[0m (\u001b[33mhossainstudy7-freelancer\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mhossai5/Ag-Ab-Affinity2/Final-Exp-Dec-18-25/wandb/run-20260104_064457-kamle31o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451/runs/kamle31o' target=\"_blank\">fold_1</a></strong> to <a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451/runs/kamle31o' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451/runs/kamle31o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767530705.741872   62293 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79078 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:25:00.0, compute capability: 8.0\n",
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/callbacks/tensorboard.py:680: UserWarning: Model failed to serialize as JSON. Ignoring... 'LlamaTransformerDecoder' object has no attribute 'rope_scaling_factor'\n",
      "  warnings.warn(f\"Model failed to serialize as JSON. Ignoring... {exc}\")\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767530717.504288   63281 service.cc:152] XLA service 0x7ffe200013f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1767530717.504355   63281 service.cc:160]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "I0000 00:00:1767530719.273245   63281 cuda_dnn.cc:529] Loaded cuDNN version 90500\n",
      "I0000 00:00:1767531017.815899   63281 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6084 - auc: 0.6307 - loss: 1.1442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m825s\u001b[0m 5s/step - accuracy: 0.6444 - auc: 0.6782 - loss: 0.8676 - val_accuracy: 0.7528 - val_auc: 0.8348 - val_loss: 0.5579\n",
      "Epoch 2/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.7333 - auc: 0.7998 - loss: 0.5483 - val_accuracy: 0.7885 - val_auc: 0.8660 - val_loss: 0.5090\n",
      "Epoch 3/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.7552 - auc: 0.8324 - loss: 0.5046 - val_accuracy: 0.7918 - val_auc: 0.8792 - val_loss: 0.4860\n",
      "Epoch 4/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.7789 - auc: 0.8558 - loss: 0.4705 - val_accuracy: 0.7984 - val_auc: 0.8879 - val_loss: 0.4539\n",
      "Epoch 5/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.7901 - auc: 0.8720 - loss: 0.4459 - val_accuracy: 0.7984 - val_auc: 0.8956 - val_loss: 0.4583\n",
      "Epoch 6/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.8096 - auc: 0.8852 - loss: 0.4224 - val_accuracy: 0.8044 - val_auc: 0.8956 - val_loss: 0.4309\n",
      "Epoch 7/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8146 - auc: 0.8922 - loss: 0.4123 - val_accuracy: 0.8149 - val_auc: 0.9014 - val_loss: 0.4172\n",
      "Epoch 8/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8200 - auc: 0.8977 - loss: 0.4018 - val_accuracy: 0.8321 - val_auc: 0.9027 - val_loss: 0.4005\n",
      "Epoch 9/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1s/step - accuracy: 0.8304 - auc: 0.9107 - loss: 0.3771 - val_accuracy: 0.8361 - val_auc: 0.9068 - val_loss: 0.4015\n",
      "Epoch 10/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.8377 - auc: 0.9144 - loss: 0.3689 - val_accuracy: 0.8268 - val_auc: 0.9056 - val_loss: 0.3964\n",
      "Epoch 11/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1s/step - accuracy: 0.8397 - auc: 0.9178 - loss: 0.3643 - val_accuracy: 0.8182 - val_auc: 0.9045 - val_loss: 0.4196\n",
      "Epoch 12/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.8443 - auc: 0.9231 - loss: 0.3523 - val_accuracy: 0.8361 - val_auc: 0.9127 - val_loss: 0.3902\n",
      "Epoch 13/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8451 - auc: 0.9237 - loss: 0.3493 - val_accuracy: 0.8202 - val_auc: 0.9080 - val_loss: 0.4019\n",
      "Epoch 14/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.8532 - auc: 0.9313 - loss: 0.3337 - val_accuracy: 0.8434 - val_auc: 0.9120 - val_loss: 0.3916\n",
      "Epoch 15/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.8574 - auc: 0.9336 - loss: 0.3297 - val_accuracy: 0.8440 - val_auc: 0.9122 - val_loss: 0.3803\n",
      "Epoch 16/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8547 - auc: 0.9355 - loss: 0.3219 - val_accuracy: 0.8414 - val_auc: 0.9162 - val_loss: 0.3736\n",
      "Epoch 17/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8623 - auc: 0.9387 - loss: 0.3163 - val_accuracy: 0.8453 - val_auc: 0.9203 - val_loss: 0.3617\n",
      "Epoch 18/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8656 - auc: 0.9417 - loss: 0.3086 - val_accuracy: 0.8526 - val_auc: 0.9223 - val_loss: 0.3594\n",
      "Epoch 19/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.8671 - auc: 0.9422 - loss: 0.3061 - val_accuracy: 0.8500 - val_auc: 0.9174 - val_loss: 0.3649\n",
      "Epoch 20/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8706 - auc: 0.9460 - loss: 0.2981 - val_accuracy: 0.8467 - val_auc: 0.9199 - val_loss: 0.3634\n",
      "Epoch 21/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8759 - auc: 0.9495 - loss: 0.2874 - val_accuracy: 0.8440 - val_auc: 0.9225 - val_loss: 0.3536\n",
      "Epoch 22/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8780 - auc: 0.9523 - loss: 0.2800 - val_accuracy: 0.8434 - val_auc: 0.9175 - val_loss: 0.3679\n",
      "Epoch 23/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8837 - auc: 0.9531 - loss: 0.2782 - val_accuracy: 0.8599 - val_auc: 0.9227 - val_loss: 0.3616\n",
      "Epoch 24/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.8871 - auc: 0.9561 - loss: 0.2697 - val_accuracy: 0.8539 - val_auc: 0.9239 - val_loss: 0.3613\n",
      "Epoch 25/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.8961 - auc: 0.9629 - loss: 0.2477 - val_accuracy: 0.8553 - val_auc: 0.9265 - val_loss: 0.3463\n",
      "Epoch 26/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8868 - auc: 0.9601 - loss: 0.2566 - val_accuracy: 0.8407 - val_auc: 0.9297 - val_loss: 0.3508\n",
      "Epoch 27/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.9005 - auc: 0.9636 - loss: 0.2461 - val_accuracy: 0.8599 - val_auc: 0.9287 - val_loss: 0.3476\n",
      "Epoch 28/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.9007 - auc: 0.9660 - loss: 0.2365 - val_accuracy: 0.8579 - val_auc: 0.9296 - val_loss: 0.3420\n",
      "Epoch 29/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.9089 - auc: 0.9712 - loss: 0.2203 - val_accuracy: 0.8612 - val_auc: 0.9330 - val_loss: 0.3381\n",
      "Epoch 30/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.9101 - auc: 0.9711 - loss: 0.2184 - val_accuracy: 0.8632 - val_auc: 0.9317 - val_loss: 0.3342\n",
      "Epoch 31/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.9073 - auc: 0.9701 - loss: 0.2226 - val_accuracy: 0.8586 - val_auc: 0.9314 - val_loss: 0.3385\n",
      "Epoch 32/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.9109 - auc: 0.9739 - loss: 0.2083 - val_accuracy: 0.8685 - val_auc: 0.9368 - val_loss: 0.3229\n",
      "Epoch 33/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.9157 - auc: 0.9761 - loss: 0.1999 - val_accuracy: 0.8738 - val_auc: 0.9328 - val_loss: 0.3369\n",
      "Epoch 34/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.9232 - auc: 0.9776 - loss: 0.1945 - val_accuracy: 0.8698 - val_auc: 0.9331 - val_loss: 0.3425\n",
      "Epoch 35/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.9266 - auc: 0.9808 - loss: 0.1787 - val_accuracy: 0.8678 - val_auc: 0.9366 - val_loss: 0.3294\n",
      "Epoch 36/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.9243 - auc: 0.9806 - loss: 0.1793 - val_accuracy: 0.8718 - val_auc: 0.9353 - val_loss: 0.3334\n",
      "Epoch 37/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9253 - auc: 0.9815 - loss: 0.1749 - val_accuracy: 0.8751 - val_auc: 0.9346 - val_loss: 0.3395\n",
      "Epoch 38/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.9332 - auc: 0.9832 - loss: 0.1670 - val_accuracy: 0.8625 - val_auc: 0.9337 - val_loss: 0.3417\n",
      "Epoch 39/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.9301 - auc: 0.9838 - loss: 0.1644 - val_accuracy: 0.8718 - val_auc: 0.9350 - val_loss: 0.3383\n",
      "Epoch 40/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.9354 - auc: 0.9856 - loss: 0.1551 - val_accuracy: 0.8784 - val_auc: 0.9357 - val_loss: 0.3428\n",
      "Epoch 41/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.9397 - auc: 0.9876 - loss: 0.1446 - val_accuracy: 0.8672 - val_auc: 0.9359 - val_loss: 0.3469\n",
      "Epoch 42/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 1s/step - accuracy: 0.9417 - auc: 0.9874 - loss: 0.1443 - val_accuracy: 0.8678 - val_auc: 0.9367 - val_loss: 0.3485\n",
      "Epoch 43/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.9498 - auc: 0.9903 - loss: 0.1288 - val_accuracy: 0.8731 - val_auc: 0.9377 - val_loss: 0.3499\n",
      "Epoch 44/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.9470 - auc: 0.9894 - loss: 0.1315 - val_accuracy: 0.8797 - val_auc: 0.9375 - val_loss: 0.3461\n",
      "Epoch 45/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - accuracy: 0.9380 - auc: 0.9871 - loss: 0.1454 - val_accuracy: 0.8731 - val_auc: 0.9370 - val_loss: 0.3547\n",
      "Epoch 46/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - accuracy: 0.9473 - auc: 0.9900 - loss: 0.1303 - val_accuracy: 0.8771 - val_auc: 0.9389 - val_loss: 0.3533\n",
      "Epoch 47/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 1s/step - accuracy: 0.9503 - auc: 0.9915 - loss: 0.1187 - val_accuracy: 0.8757 - val_auc: 0.9387 - val_loss: 0.3518\n",
      "Epoch 48/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.9550 - auc: 0.9927 - loss: 0.1097 - val_accuracy: 0.8757 - val_auc: 0.9390 - val_loss: 0.3540\n",
      "Epoch 49/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.9579 - auc: 0.9928 - loss: 0.1073 - val_accuracy: 0.8870 - val_auc: 0.9385 - val_loss: 0.3687\n",
      "Epoch 50/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.9564 - auc: 0.9927 - loss: 0.1088 - val_accuracy: 0.8757 - val_auc: 0.9384 - val_loss: 0.3513\n",
      "Epoch 51/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.9549 - auc: 0.9933 - loss: 0.1065 - val_accuracy: 0.8744 - val_auc: 0.9397 - val_loss: 0.3729\n",
      "Epoch 52/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.9549 - auc: 0.9930 - loss: 0.1080 - val_accuracy: 0.8698 - val_auc: 0.9432 - val_loss: 0.3404\n",
      "Epoch 53/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.9628 - auc: 0.9939 - loss: 0.1001 - val_accuracy: 0.8705 - val_auc: 0.9435 - val_loss: 0.3347\n",
      "Epoch 54/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.9593 - auc: 0.9928 - loss: 0.1079 - val_accuracy: 0.8797 - val_auc: 0.9402 - val_loss: 0.3769\n",
      "Epoch 55/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - accuracy: 0.9623 - auc: 0.9942 - loss: 0.0963 - val_accuracy: 0.8764 - val_auc: 0.9386 - val_loss: 0.3808\n",
      "Epoch 56/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - accuracy: 0.9686 - auc: 0.9955 - loss: 0.0851 - val_accuracy: 0.8605 - val_auc: 0.9339 - val_loss: 0.4287\n",
      "Epoch 57/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.9633 - auc: 0.9938 - loss: 0.0979 - val_accuracy: 0.8645 - val_auc: 0.9371 - val_loss: 0.3942\n",
      "Epoch 58/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.9674 - auc: 0.9958 - loss: 0.0825 - val_accuracy: 0.8883 - val_auc: 0.9389 - val_loss: 0.3877\n",
      "Epoch 59/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.9671 - auc: 0.9962 - loss: 0.0787 - val_accuracy: 0.8903 - val_auc: 0.9413 - val_loss: 0.3751\n",
      "Epoch 60/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - accuracy: 0.9633 - auc: 0.9948 - loss: 0.0899 - val_accuracy: 0.8824 - val_auc: 0.9404 - val_loss: 0.3873\n",
      "Epoch 61/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - accuracy: 0.9716 - auc: 0.9970 - loss: 0.0712 - val_accuracy: 0.8837 - val_auc: 0.9379 - val_loss: 0.4383\n",
      "Epoch 62/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.9732 - auc: 0.9971 - loss: 0.0676 - val_accuracy: 0.8830 - val_auc: 0.9393 - val_loss: 0.4172\n",
      "Epoch 63/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9744 - auc: 0.9974 - loss: 0.0665 - val_accuracy: 0.8870 - val_auc: 0.9399 - val_loss: 0.4186\n",
      "Epoch 64/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9721 - auc: 0.9971 - loss: 0.0676 - val_accuracy: 0.8896 - val_auc: 0.9419 - val_loss: 0.4029\n",
      "Epoch 65/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.9780 - auc: 0.9976 - loss: 0.0622 - val_accuracy: 0.8790 - val_auc: 0.9384 - val_loss: 0.4261\n",
      "Epoch 66/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.9772 - auc: 0.9978 - loss: 0.0620 - val_accuracy: 0.8757 - val_auc: 0.9308 - val_loss: 0.4912\n",
      "Epoch 67/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.9679 - auc: 0.9960 - loss: 0.0809 - val_accuracy: 0.8837 - val_auc: 0.9364 - val_loss: 0.4213\n",
      "Epoch 68/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.9798 - auc: 0.9980 - loss: 0.0560 - val_accuracy: 0.8870 - val_auc: 0.9405 - val_loss: 0.4280\n",
      "Epoch 69/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.9805 - auc: 0.9983 - loss: 0.0531 - val_accuracy: 0.8797 - val_auc: 0.9337 - val_loss: 0.4884\n",
      "Epoch 70/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.9807 - auc: 0.9984 - loss: 0.0516 - val_accuracy: 0.8863 - val_auc: 0.9380 - val_loss: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 793ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 946ms/step\n",
      "{'fold': 1, 'accuracy': 0.8863185723727693, 'f1': 0.8842530282637954, 'recall': 0.8678996036988111, 'precision': 0.9012345679012346, 'roc_auc': 0.9442932978269833, 'aupr': 0.9408356763781383, 'specificity': 0.9047619047619048}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>aupr</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██▇█████████</td></tr><tr><td>epoch/auc</td><td>▁▄▄▅▅▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>██▇▇▆▆▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▁▂▄▃▄▃▄▅▅▅▅▅▄▅▅▄▆▆▆▇▆▆▇▇▇▆▇▇▇█▇▆▆▇██▇█</td></tr><tr><td>epoch/val_auc</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇███▇██████████▇█████▇</td></tr><tr><td>epoch/val_loss</td><td>█▇▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▁▂▄▃▂▄▃▄▄▄▅</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.88632</td></tr><tr><td>aupr</td><td>0.94084</td></tr><tr><td>epoch/accuracy</td><td>0.98066</td></tr><tr><td>epoch/auc</td><td>0.99841</td></tr><tr><td>epoch/epoch</td><td>69</td></tr><tr><td>epoch/learning_rate</td><td>5e-05</td></tr><tr><td>epoch/loss</td><td>0.0516</td></tr><tr><td>epoch/val_accuracy</td><td>0.88632</td></tr><tr><td>epoch/val_auc</td><td>0.938</td></tr><tr><td>epoch/val_loss</td><td>0.44441</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_1</strong> at: <a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451/runs/kamle31o' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451/runs/kamle31o</a><br> View project at: <a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260104_064457-kamle31o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      " Fold 2 / 5\n",
      "==========================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mhossai5/Ag-Ab-Affinity2/Final-Exp-Dec-18-25/wandb/run-20260104_092455-3urn1c4w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451/runs/3urn1c4w' target=\"_blank\">fold_2</a></strong> to <a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451/runs/3urn1c4w' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/SabDab2-RLEAAI-ESM_T36-20260104-064451/runs/3urn1c4w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/callbacks/tensorboard.py:680: UserWarning: Model failed to serialize as JSON. Ignoring... 'LlamaTransformerDecoder' object has no attribute 'rope_scaling_factor'\n",
      "  warnings.warn(f\"Model failed to serialize as JSON. Ignoring... {exc}\")\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960ms/step - accuracy: 0.5762 - auc: 0.5986 - loss: 1.2980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.6290 - auc: 0.6623 - loss: 0.9363 - val_accuracy: 0.7515 - val_auc: 0.8141 - val_loss: 0.5505\n",
      "Epoch 2/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.7384 - auc: 0.8089 - loss: 0.5364 - val_accuracy: 0.7773 - val_auc: 0.8438 - val_loss: 0.5333\n",
      "Epoch 3/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.7586 - auc: 0.8359 - loss: 0.4990 - val_accuracy: 0.7799 - val_auc: 0.8613 - val_loss: 0.5095\n",
      "Epoch 4/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.7812 - auc: 0.8610 - loss: 0.4650 - val_accuracy: 0.7918 - val_auc: 0.8756 - val_loss: 0.4964\n",
      "Epoch 5/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.7913 - auc: 0.8727 - loss: 0.4437 - val_accuracy: 0.8050 - val_auc: 0.8836 - val_loss: 0.4721\n",
      "Epoch 6/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8081 - auc: 0.8883 - loss: 0.4186 - val_accuracy: 0.7944 - val_auc: 0.8889 - val_loss: 0.4703\n",
      "Epoch 7/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8192 - auc: 0.8977 - loss: 0.4031 - val_accuracy: 0.8235 - val_auc: 0.8956 - val_loss: 0.4351\n",
      "Epoch 8/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.8210 - auc: 0.9028 - loss: 0.3931 - val_accuracy: 0.8334 - val_auc: 0.8997 - val_loss: 0.4260\n",
      "Epoch 9/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8309 - auc: 0.9123 - loss: 0.3737 - val_accuracy: 0.8301 - val_auc: 0.8976 - val_loss: 0.4148\n",
      "Epoch 10/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8407 - auc: 0.9175 - loss: 0.3646 - val_accuracy: 0.8110 - val_auc: 0.9008 - val_loss: 0.4218\n",
      "Epoch 11/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.8417 - auc: 0.9194 - loss: 0.3592 - val_accuracy: 0.8334 - val_auc: 0.9035 - val_loss: 0.4048\n",
      "Epoch 12/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8440 - auc: 0.9205 - loss: 0.3576 - val_accuracy: 0.8440 - val_auc: 0.9074 - val_loss: 0.4017\n",
      "Epoch 13/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8491 - auc: 0.9272 - loss: 0.3432 - val_accuracy: 0.8348 - val_auc: 0.9090 - val_loss: 0.3949\n",
      "Epoch 14/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8501 - auc: 0.9305 - loss: 0.3352 - val_accuracy: 0.8407 - val_auc: 0.9123 - val_loss: 0.3865\n",
      "Epoch 15/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.8584 - auc: 0.9365 - loss: 0.3206 - val_accuracy: 0.8315 - val_auc: 0.9078 - val_loss: 0.3910\n",
      "Epoch 16/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.8590 - auc: 0.9381 - loss: 0.3167 - val_accuracy: 0.8420 - val_auc: 0.9123 - val_loss: 0.3831\n",
      "Epoch 17/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8676 - auc: 0.9416 - loss: 0.3084 - val_accuracy: 0.8341 - val_auc: 0.9144 - val_loss: 0.3812\n",
      "Epoch 18/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8698 - auc: 0.9452 - loss: 0.2996 - val_accuracy: 0.8453 - val_auc: 0.9159 - val_loss: 0.3724\n",
      "Epoch 19/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8706 - auc: 0.9479 - loss: 0.2921 - val_accuracy: 0.8480 - val_auc: 0.9153 - val_loss: 0.3731\n",
      "Epoch 20/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8784 - auc: 0.9506 - loss: 0.2838 - val_accuracy: 0.8381 - val_auc: 0.9151 - val_loss: 0.3794\n",
      "Epoch 21/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.8795 - auc: 0.9539 - loss: 0.2762 - val_accuracy: 0.8407 - val_auc: 0.9148 - val_loss: 0.3790\n",
      "Epoch 22/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8833 - auc: 0.9549 - loss: 0.2736 - val_accuracy: 0.8493 - val_auc: 0.9171 - val_loss: 0.3667\n",
      "Epoch 23/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8853 - auc: 0.9578 - loss: 0.2623 - val_accuracy: 0.8394 - val_auc: 0.9183 - val_loss: 0.3738\n",
      "Epoch 24/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.8881 - auc: 0.9592 - loss: 0.2588 - val_accuracy: 0.8467 - val_auc: 0.9192 - val_loss: 0.3665\n",
      "Epoch 25/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8967 - auc: 0.9633 - loss: 0.2472 - val_accuracy: 0.8434 - val_auc: 0.9189 - val_loss: 0.3659\n",
      "Epoch 26/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8937 - auc: 0.9622 - loss: 0.2482 - val_accuracy: 0.8605 - val_auc: 0.9220 - val_loss: 0.3579\n",
      "Epoch 27/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.8990 - auc: 0.9668 - loss: 0.2342 - val_accuracy: 0.8486 - val_auc: 0.9217 - val_loss: 0.3672\n",
      "Epoch 28/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.9040 - auc: 0.9690 - loss: 0.2266 - val_accuracy: 0.8387 - val_auc: 0.9227 - val_loss: 0.3632\n",
      "Epoch 29/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9017 - auc: 0.9690 - loss: 0.2262 - val_accuracy: 0.8447 - val_auc: 0.9173 - val_loss: 0.3805\n",
      "Epoch 30/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9028 - auc: 0.9687 - loss: 0.2270 - val_accuracy: 0.8579 - val_auc: 0.9244 - val_loss: 0.3592\n",
      "Epoch 31/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.9152 - auc: 0.9751 - loss: 0.2040 - val_accuracy: 0.8592 - val_auc: 0.9274 - val_loss: 0.3594\n",
      "Epoch 32/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.9121 - auc: 0.9759 - loss: 0.1988 - val_accuracy: 0.8711 - val_auc: 0.9290 - val_loss: 0.3549\n",
      "Epoch 33/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.9230 - auc: 0.9779 - loss: 0.1911 - val_accuracy: 0.8605 - val_auc: 0.9279 - val_loss: 0.3577\n",
      "Epoch 34/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9225 - auc: 0.9801 - loss: 0.1825 - val_accuracy: 0.8705 - val_auc: 0.9302 - val_loss: 0.3487\n",
      "Epoch 35/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.9238 - auc: 0.9805 - loss: 0.1799 - val_accuracy: 0.8605 - val_auc: 0.9285 - val_loss: 0.3631\n",
      "Epoch 36/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.9275 - auc: 0.9811 - loss: 0.1758 - val_accuracy: 0.8586 - val_auc: 0.9323 - val_loss: 0.3410\n",
      "Epoch 37/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.9341 - auc: 0.9837 - loss: 0.1651 - val_accuracy: 0.8592 - val_auc: 0.9281 - val_loss: 0.3694\n",
      "Epoch 38/70\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - accuracy: 0.9395 - auc: 0.9860 - loss: 0.1528 - val_accuracy: 0.8645 - val_auc: 0.9331 - val_loss: 0.3578\n",
      "Epoch 39/70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score,\n",
    "    roc_auc_score, matthews_corrcoef, confusion_matrix,\n",
    "    average_precision_score\n",
    ")\n",
    "CONFIG['n_splits'] =5\n",
    "# =============================================================\n",
    "#  K-FOLD CROSS VALIDATION SETTINGS\n",
    "# =============================================================\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_splits'], shuffle=True, random_state=42)\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "# =============================================================\n",
    "#  MAIN LOOP\n",
    "# =============================================================\n",
    "for fold,(train_idx, valid_idx) in enumerate(skf.split(df, df[\"label\"]),1):\n",
    "    print(f\"\\n==========================\")\n",
    "    print(f\" Fold {fold} / {CONFIG['n_splits']}\")\n",
    "    print(f\"==========================\")\n",
    "    run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            name=f\"fold_{fold}\",\n",
    "            group=\"KFold-CV\",\n",
    "            config={**CONFIG, \"fold\": fold},\n",
    "            reinit=True\n",
    "        )\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    valid_df = df.iloc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Loaders\n",
    "    # ---------------------------------------\n",
    "    train_loader = DataSequenceLoader(\n",
    "        train_df, \n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        max_len = CONFIG['max_len'], \n",
    "        shuffle=True)\n",
    "    valid_loader = DataSequenceLoader(\n",
    "        valid_df, \n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        max_len = CONFIG['max_len'], \n",
    "        shuffle=False)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Build a FRESH MODEL per fold\n",
    "    # ---------------------------------------\n",
    "    model = build_model()\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(CONFIG[\"learning_rate\"]),\n",
    "        loss=CONFIG[\"loss\"],\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            tf.keras.metrics.AUC(name=\"auc\")\n",
    "        ]\n",
    "    )\n",
    "    # -----------------------------------------------------\n",
    "    # Callbacks\n",
    "    # -----------------------------------------------------\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(OUT_PATH, \"logs\", f\"fold_{fold}\")\n",
    "    )\n",
    "\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\n",
    "            OUT_PATH, \"weights\",\n",
    "            f\"weights_fold{fold}-best.weights.h5\"\n",
    "        ),\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "    # ---------------------------------------\n",
    "    # Train\n",
    "    # ---------------------------------------\n",
    "    history = model.fit(\n",
    "        train_loader,\n",
    "        validation_data=valid_loader,\n",
    "        epochs=CONFIG[\"epochs\"],\n",
    "        callbacks=[\n",
    "            tb_callback,\n",
    "            checkpoint_cb,\n",
    "            WandbMetricsLogger(log_freq=\"epoch\")\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.save_weights(\n",
    "        os.path.join(\n",
    "            OUT_PATH,\n",
    "            \"weights\",\n",
    "            f\"weights_fold{fold}-last.weights.h5\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Evaluation\n",
    "    # -----------------------------------------------------\n",
    "    y_pred_prob = model.predict(valid_loader).ravel()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    y_true = valid_df[\"label\"].values\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"fold\": fold,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_pred_prob),\n",
    "        \"aupr\": average_precision_score(y_true, y_pred_prob),\n",
    "        \"specificity\": specificity\n",
    "    }\n",
    "\n",
    "    # Log fold metrics to W&B\n",
    "    wandb.log(metrics_dict)\n",
    "\n",
    "    print(metrics_dict)\n",
    "    all_metrics.append(metrics_dict)\n",
    "\n",
    "    run.finish()\n",
    "\n",
    "# =========================================================\n",
    "# Save All Metrics\n",
    "# =========================================================\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "avg_row = metrics_df.mean(numeric_only=True)\n",
    "metrics_df = pd.concat(\n",
    "    [metrics_df, avg_row.to_frame().T],\n",
    "    ignore_index=True\n",
    ")\n",
    "metrics_df.loc[metrics_df.index[-1], \"fold\"] = \"Average\"\n",
    "\n",
    "metrics_df.to_csv(\n",
    "    os.path.join(\n",
    "        OUT_PATH,\n",
    "        f\"{PROJECT_NAME}-kfold_classification_metrics.csv\"\n",
    "    ),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nAll fold metrics saved.\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaccc9d-6db3-4b94-89ac-81a59e242356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "#  EVALUATION (POST-TRAINING)\n",
    "# =============================================================\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score,\n",
    "    roc_auc_score, matthews_corrcoef,\n",
    "    confusion_matrix, average_precision_score\n",
    ")\n",
    "\n",
    "all_metrics = []\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_splits'], shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (_, valid_idx) in enumerate(\n",
    "        skf.split(df, df[\"Interaction\"]), 1):\n",
    "\n",
    "    print(f\"\\nEvaluating Fold {fold}\")\n",
    "\n",
    "    valid_df = df.iloc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "    valid_loader = DataSequenceLoader(\n",
    "        valid_df,\n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        max_len=CONFIG[\"max_len\"],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Rebuild model & load best weights\n",
    "    model = build_model()\n",
    "    model.load_weights(\n",
    "        os.path.join(\n",
    "            OUT_PATH, \"weights\",\n",
    "            f\"weights_fold{fold}-best.weights.h5\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Prediction\n",
    "    y_prob = model.predict(valid_loader).ravel()\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    y_true = valid_df[\"label\"].values\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"fold\": fold,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),     # sensitivity\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"mcc\": matthews_corrcoef(y_true, y_pred),\n",
    "        \"auc\": roc_auc_score(y_true, y_prob),\n",
    "        \"prauc\": average_precision_score(y_true, y_prob),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0.0,\n",
    "        \"sensitivity\": tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    }\n",
    "\n",
    "    print(metrics_dict)\n",
    "    all_metrics.append(metrics_dict)\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "avg_row = metrics_df.mean(numeric_only=True)\n",
    "avg_row[\"fold\"] = \"Average\"\n",
    "\n",
    "metrics_df = pd.concat(\n",
    "    [metrics_df, avg_row.to_frame().T],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "metrics_df.to_csv(\n",
    "    os.path.join(\n",
    "        OUT_PATH,\n",
    "        f\"{PROJECT_NAME}-kfold_evaluation_metrics.csv\"\n",
    "    ),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation completed and saved.\")\n",
    "metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-antibody_dl]",
   "language": "python",
   "name": "conda-env-.conda-antibody_dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
