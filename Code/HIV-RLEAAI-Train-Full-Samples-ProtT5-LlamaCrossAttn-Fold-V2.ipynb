{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efac3282-17b1-45e0-ae4a-1034adcf63c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/knlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-04 14:53:16.482746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764881596.495679  118629 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764881596.499885  118629 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] ='tensorflow'\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from keras import layers, Model, Input\n",
    "from keras_hub.src.models.llama.llama_decoder import LlamaTransformerDecoder\n",
    "from keras_hub.src.models.llama.llama_layernorm import LlamaLayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18607b-2f76-46ab-b443-465dfee810cc",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fafc18e-c6e4-49aa-8aac-4ccfc9cedc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "DATA_PATH = '../RLEAAI/data/HIV/'\n",
    "loaded_data = {}\n",
    "with h5py.File(os.path.join(DATA_PATH,\"HIV-RLEAAI-ProtT5-Full.h5\"), 'r') as hf:\n",
    "    for seq in hf.keys():\n",
    "        loaded_data[seq] = hf[seq][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4023231-5c03-4f31-aa67-504f145b1cab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibody_seq</th>\n",
       "      <th>virus_seq</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QMKLMQSGGVMVRPGESATLSCVASGFDFSRNGFEWLRQGPGKGLQ...</td>\n",
       "      <td>MRVMGIRKNYQHLWREGILLLGILMICSAADNLWVTVYYGVPVWRE...</td>\n",
       "      <td>0</td>\n",
       "      <td>seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QPQLQESGPGLVEASETLSLTCTVSGDSTGRCNYFWGWVRQPPGKG...</td>\n",
       "      <td>MRVRGIPRNWPQWWIWGILGFWMIIICRVVGNMWVTVYYGVPVWTD...</td>\n",
       "      <td>0</td>\n",
       "      <td>seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QVQLLQSGAAVTKPGASVRVSCEASGYNIRDYFIHWWRQAPGQGLQ...</td>\n",
       "      <td>MRVMEIQRNCQHWWIWGILGFWMLMICNVRGWWVTVYYGVPVWKEA...</td>\n",
       "      <td>1</td>\n",
       "      <td>seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QSQLQESGPRLVEASETLSLTCNVSGESTGACTYFWGWVRQAPGKG...</td>\n",
       "      <td>MRVKETQMNWPNLWKLGTLILGLVIICSASXNLWVTVYYGVPVWRD...</td>\n",
       "      <td>1</td>\n",
       "      <td>seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QEQLVESGGGVVQPGGSLRLSCLASGFTFHKYGMHWVRQAPGKGLE...</td>\n",
       "      <td>MRVTGTQRNCQQWWIWIWIILGFWWMLMMCKGEKLWVTVYYGVPVW...</td>\n",
       "      <td>1</td>\n",
       "      <td>seen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        antibody_seq  \\\n",
       "0  QMKLMQSGGVMVRPGESATLSCVASGFDFSRNGFEWLRQGPGKGLQ...   \n",
       "1  QPQLQESGPGLVEASETLSLTCTVSGDSTGRCNYFWGWVRQPPGKG...   \n",
       "2  QVQLLQSGAAVTKPGASVRVSCEASGYNIRDYFIHWWRQAPGQGLQ...   \n",
       "3  QSQLQESGPRLVEASETLSLTCNVSGESTGACTYFWGWVRQAPGKG...   \n",
       "4  QEQLVESGGGVVQPGGSLRLSCLASGFTFHKYGMHWVRQAPGKGLE...   \n",
       "\n",
       "                                           virus_seq  label split  \n",
       "0  MRVMGIRKNYQHLWREGILLLGILMICSAADNLWVTVYYGVPVWRE...      0  seen  \n",
       "1  MRVRGIPRNWPQWWIWGILGFWMIIICRVVGNMWVTVYYGVPVWTD...      0  seen  \n",
       "2  MRVMEIQRNCQHWWIWGILGFWMLMICNVRGWWVTVYYGVPVWKEA...      1  seen  \n",
       "3  MRVKETQMNWPNLWKLGTLILGLVIICSASXNLWVTVYYGVPVWRD...      1  seen  \n",
       "4  MRVTGTQRNCQQWWIWIWIILGFWWMLMMCKGEKLWVTVYYGVPVW...      1  seen  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"https://github.com/zhouyu9931/RLEAAI/raw/refs/heads/main/data/dataset_hiv.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cae6a53-8e6e-4f82-96fb-970c6bf9c32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "def process_sequence_tf(x_emb, max_len=1024, pad_value=0.0):\n",
    "    seq_len = x_emb.shape[0]\n",
    "    \n",
    "    if seq_len > max_len:\n",
    "        # truncate\n",
    "        x_emb = tf.convert_to_tensor(x_emb[:max_len])\n",
    "        mask = tf.ones([max_len], dtype=tf.float32)\n",
    "    else:\n",
    "        # pad\n",
    "        pad_len = max_len - seq_len\n",
    "        paddings = [[0, pad_len], [0, 0]]\n",
    "        x_emb = tf.pad(x_emb, paddings, constant_values=pad_value)\n",
    "        mask = tf.pad(tf.ones([seq_len], dtype=tf.float32), [[0, pad_len]], constant_values=0.0)\n",
    "    \n",
    "    return x_emb, mask\n",
    "\n",
    "# -----------------------------\n",
    "# Keras Sequence Loader\n",
    "# -----------------------------\n",
    "class DataSequenceLoader(Sequence):\n",
    "    def __init__(self, df, batch_size=32, shuffle=True, max_len=512, pad_value=0.0):\n",
    "        self.x1_emb = df[\"antibody_seq\"].values\n",
    "        self.x2_emb = df[\"virus_seq\"].values\n",
    "        self.labels = df[\"label\"].values\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.max_len = max_len\n",
    "        self.pad_value = pad_value\n",
    "        self.indices = np.arange(len(df))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "\n",
    "        x1_list, x2_list, m1_list, m2_list = [], [], [], []\n",
    "        labels_list = []\n",
    "\n",
    "        for i in batch_idx:\n",
    "            emb1 = loaded_data[self.x1_emb[i]].reshape(-1, 1024)\n",
    "            emb2 = loaded_data[self.x2_emb[i]].reshape(-1, 1024)\n",
    "\n",
    "            # ---- process embeddings + mask ----\n",
    "            x1_pad, mask1 = process_sequence_tf(emb1, max_len=self.max_len, pad_value=self.pad_value)\n",
    "            x2_pad, mask2 = process_sequence_tf(emb2, max_len=self.max_len, pad_value=self.pad_value)\n",
    "\n",
    "            x1_list.append(x1_pad.numpy())\n",
    "            x2_list.append(x2_pad.numpy())\n",
    "            m1_list.append(mask1.numpy())\n",
    "            m2_list.append(mask2.numpy())\n",
    "            labels_list.append(self.labels[i])\n",
    "\n",
    "        # Convert lists to arrays for batch\n",
    "        x1_batch = np.stack(x1_list, axis=0)\n",
    "        x2_batch = np.stack(x2_list, axis=0)\n",
    "        m1_batch = np.stack(m1_list, axis=0)\n",
    "        m2_batch = np.stack(m2_list, axis=0)\n",
    "        labels_batch = np.array(labels_list)\n",
    "\n",
    "        return (x1_batch, x2_batch, m1_batch, m2_batch), labels_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a643463-b27a-44ba-b50f-6ae7081dd5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loader  = DataSequenceLoader(df,batch_size=4,shuffle =True)\n",
    "# for x in loader:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e053595-ecc9-4960-8d23-7f77235440b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Hybrid Pooling Layer (Max + Avg)\n",
    "# -------------------------------------------------------------------\n",
    "class HybridPooling(layers.Layer):\n",
    "    def call(self, x):\n",
    "        max_pooled = keras.ops.max(x, axis=1)\n",
    "        avg_pooled = keras.ops.mean(x, axis=1)\n",
    "        return keras.ops.concatenate([max_pooled, avg_pooled], axis=-1)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Conv Block (Conv1D → ReLU → Dropout → MaxPool)\n",
    "# -------------------------------------------------------------------\n",
    "def conv_block(x, filters =  100, kernel_sz =20, stride =10, dropout = 0.5):\n",
    "    x = layers.Conv1D(filters, kernel_sz, strides=stride)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=1, padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Cross-attention (Query=X1, Key=X2, Value=X2)\n",
    "# -------------------------------------------------------------------\n",
    "def cross_attention_block(query, key, value, mask, num_heads =4, key_dim =32):\n",
    "    attn = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, \n",
    "        key_dim=key_dim,\n",
    "        dropout=0.0,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        use_bias=True,\n",
    "        # flash_attention=None,  # if GPU supports\n",
    "    )(query, key, value, key_mask=mask, value_mask=mask)\n",
    "    return attn\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# LLaMA Self-Attention Block\n",
    "# -------------------------------------------------------------------\n",
    "def llama_self_attention(x, mask, hidden_dim =100, num_heads = 4):\n",
    "    # single LLaMA decoder layer\n",
    "    llama = LlamaTransformerDecoder(\n",
    "        intermediate_dim=hidden_dim * 4,\n",
    "        # num_heads=num_heads,\n",
    "        num_query_heads=8,\n",
    "        num_key_value_heads=2,\n",
    "        dropout=0.0,\n",
    "        layer_norm_epsilon=1e-5,\n",
    "        activation=\"silu\"\n",
    "    )\n",
    "    return llama(x, decoder_padding_mask=mask)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Functional API Model (PyTorch → Keras Conversion)\n",
    "# -------------------------------------------------------------------\n",
    "def build_model(\n",
    "    input_dim=1024,\n",
    "    conv_out=100,\n",
    "    kernel_sz=20,\n",
    "    stride=10,\n",
    "    heads=4,\n",
    "    d_dim=32,\n",
    "    drop_pool=0.4,\n",
    "    drop_linear=0.4\n",
    "):\n",
    "    # Inputs\n",
    "    inp1 = Input((None, 1024))\n",
    "    inp2 = Input((None, 1024))\n",
    "    mask1 = Input((None, ))\n",
    "    mask2 = Input((None, ))\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 1) Convolutional features\n",
    "    # ---------------------------------------------------\n",
    "    # p1 = conv_block(inp1, conv_out, kernel_sz, stride, drop_pool)\n",
    "    # p2 = conv_block(inp2, conv_out, kernel_sz, stride, drop_pool)\n",
    "    x_dim = 384\n",
    "    p1 = layers.Dense(x_dim, use_bias=False,name='stem1')(inp1)\n",
    "    p1 = layers.BatchNormalization(momentum=0.95,name='bn1')(p1)\n",
    "    \n",
    "    p2 = layers.Dense(x_dim, use_bias=False,name='stem2')(inp2)\n",
    "    p2 = layers.BatchNormalization(momentum=0.95,name='bn2')(p2)\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 2) Self Attention using LLaMA blocks\n",
    "    # ---------------------------------------------------\n",
    "    s1 = llama_self_attention(p1, mask1, conv_out, heads)\n",
    "    s2 = llama_self_attention(p2, mask2, conv_out, heads)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 3) Cross Attention (1→2 and 2→1)\n",
    "    # ---------------------------------------------------\n",
    "    c1 = cross_attention_block(p1, p2, p2, mask2, heads, d_dim)\n",
    "    c2 = cross_attention_block(p2, p1, p1, mask1, heads, d_dim)\n",
    "\n",
    "    # Add residual (same as PyTorch + skip)\n",
    "    sc1 = layers.Add()([s1, c1])\n",
    "    sc2 = layers.Add()([s2, c2])\n",
    "\n",
    "    sc1 = layers.Dropout(drop_pool)(sc1)\n",
    "    sc2 = layers.Dropout(drop_pool)(sc2)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 4) Hybrid Pooling (max + mean)\n",
    "    # ---------------------------------------------------\n",
    "    h1 = HybridPooling()(sc1)\n",
    "    h2 = HybridPooling()(sc2)\n",
    "\n",
    "    merged = layers.Concatenate()([h1, h2])\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 5) MLP Head\n",
    "    # ---------------------------------------------------\n",
    "    x = layers.Dense(256, activation=\"relu\")(merged)\n",
    "    x = layers.Dropout(drop_linear)(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(drop_linear)(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs=[inp1, inp2, mask1, mask2], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "922455a9-aac9-46de-93ca-06b4fa5877a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== FOLD 1 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764835330.435296    8819 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79078 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "/home/mhossai5/.conda/envs/knlp/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764835340.199419   13582 service.cc:148] XLA service 0x7ffe74001e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1764835340.200734   13582 service.cc:156]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "I0000 00:00:1764835341.304179   13582 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/622\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:00:42\u001b[0m 197s/step - accuracy: 0.5625 - loss: 2.3832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764835531.688784   13582 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.5163 - loss: 1.5295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 534ms/step - accuracy: 0.5163 - loss: 1.5287 - val_accuracy: 0.6965 - val_loss: 0.6416\n",
      "Epoch 2/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.6226 - loss: 0.6527 - val_accuracy: 0.7126 - val_loss: 0.6199\n",
      "Epoch 3/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.6621 - loss: 0.6168 - val_accuracy: 0.7301 - val_loss: 0.5799\n",
      "Epoch 4/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.6959 - loss: 0.5805 - val_accuracy: 0.7388 - val_loss: 0.5636\n",
      "Epoch 5/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7117 - loss: 0.5659 - val_accuracy: 0.7410 - val_loss: 0.5459\n",
      "Epoch 6/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7089 - loss: 0.5616 - val_accuracy: 0.7498 - val_loss: 0.5429\n",
      "Epoch 7/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7315 - loss: 0.5385 - val_accuracy: 0.7462 - val_loss: 0.5364\n",
      "Epoch 8/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7365 - loss: 0.5357 - val_accuracy: 0.7454 - val_loss: 0.5321\n",
      "Epoch 9/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7399 - loss: 0.5251 - val_accuracy: 0.7535 - val_loss: 0.5273\n",
      "Epoch 10/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7448 - loss: 0.5184 - val_accuracy: 0.7553 - val_loss: 0.5246\n",
      "Epoch 11/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7470 - loss: 0.5097 - val_accuracy: 0.7597 - val_loss: 0.5148\n",
      "Epoch 12/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7586 - loss: 0.5060 - val_accuracy: 0.7571 - val_loss: 0.5157\n",
      "Epoch 13/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7497 - loss: 0.5065 - val_accuracy: 0.7629 - val_loss: 0.5049\n",
      "Epoch 14/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.7478 - loss: 0.5080 - val_accuracy: 0.7649 - val_loss: 0.4962\n",
      "Epoch 15/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7594 - loss: 0.4898 - val_accuracy: 0.7676 - val_loss: 0.5138\n",
      "Epoch 16/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7623 - loss: 0.4898 - val_accuracy: 0.7740 - val_loss: 0.5007\n",
      "Epoch 17/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.7679 - loss: 0.4812 - val_accuracy: 0.7736 - val_loss: 0.4944\n",
      "Epoch 18/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7672 - loss: 0.4778 - val_accuracy: 0.7770 - val_loss: 0.4928\n",
      "Epoch 19/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7725 - loss: 0.4761 - val_accuracy: 0.7784 - val_loss: 0.4907\n",
      "Epoch 21/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.7798 - loss: 0.4657 - val_accuracy: 0.7812 - val_loss: 0.4721\n",
      "Epoch 22/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7770 - loss: 0.4681 - val_accuracy: 0.7750 - val_loss: 0.4858\n",
      "Epoch 23/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7829 - loss: 0.4577 - val_accuracy: 0.7818 - val_loss: 0.4726\n",
      "Epoch 24/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 130ms/step - accuracy: 0.7771 - loss: 0.4621 - val_accuracy: 0.7915 - val_loss: 0.4665\n",
      "Epoch 25/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.7821 - loss: 0.4622 - val_accuracy: 0.7889 - val_loss: 0.4665\n",
      "Epoch 26/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7872 - loss: 0.4512 - val_accuracy: 0.7841 - val_loss: 0.4683\n",
      "Epoch 27/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.7862 - loss: 0.4534 - val_accuracy: 0.7899 - val_loss: 0.4567\n",
      "Epoch 28/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7836 - loss: 0.4565 - val_accuracy: 0.8012 - val_loss: 0.4652\n",
      "Epoch 29/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7874 - loss: 0.4504 - val_accuracy: 0.7971 - val_loss: 0.4603\n",
      "Epoch 30/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7929 - loss: 0.4429 - val_accuracy: 0.7875 - val_loss: 0.4733\n",
      "Epoch 31/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.7888 - loss: 0.4420 - val_accuracy: 0.7961 - val_loss: 0.4553\n",
      "Epoch 32/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8001 - loss: 0.4327 - val_accuracy: 0.7967 - val_loss: 0.4516\n",
      "Epoch 33/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7953 - loss: 0.4350 - val_accuracy: 0.7959 - val_loss: 0.4524\n",
      "Epoch 34/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8015 - loss: 0.4303 - val_accuracy: 0.8070 - val_loss: 0.4466\n",
      "Epoch 35/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7951 - loss: 0.4325 - val_accuracy: 0.7963 - val_loss: 0.4432\n",
      "Epoch 36/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8056 - loss: 0.4243 - val_accuracy: 0.7905 - val_loss: 0.4570\n",
      "Epoch 37/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.7969 - loss: 0.4253 - val_accuracy: 0.8144 - val_loss: 0.4389\n",
      "Epoch 38/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8110 - loss: 0.4135 - val_accuracy: 0.8028 - val_loss: 0.4407\n",
      "Epoch 39/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8025 - loss: 0.4210 - val_accuracy: 0.8130 - val_loss: 0.4318\n",
      "Epoch 40/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8101 - loss: 0.4138 - val_accuracy: 0.8106 - val_loss: 0.4380\n",
      "Epoch 41/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8095 - loss: 0.4128 - val_accuracy: 0.8080 - val_loss: 0.4342\n",
      "Epoch 42/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 128ms/step - accuracy: 0.8048 - loss: 0.4166 - val_accuracy: 0.8128 - val_loss: 0.4269\n",
      "Epoch 43/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8120 - loss: 0.4088 - val_accuracy: 0.7979 - val_loss: 0.4333\n",
      "Epoch 44/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8090 - loss: 0.4109 - val_accuracy: 0.8062 - val_loss: 0.4300\n",
      "Epoch 45/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8163 - loss: 0.3976 - val_accuracy: 0.8177 - val_loss: 0.4199\n",
      "Epoch 46/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 125ms/step - accuracy: 0.8123 - loss: 0.4034 - val_accuracy: 0.8181 - val_loss: 0.4179\n",
      "Epoch 47/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 121ms/step - accuracy: 0.8151 - loss: 0.4028 - val_accuracy: 0.8243 - val_loss: 0.4126\n",
      "Epoch 48/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8159 - loss: 0.3927 - val_accuracy: 0.8108 - val_loss: 0.4237\n",
      "Epoch 49/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 120ms/step - accuracy: 0.8168 - loss: 0.3981 - val_accuracy: 0.8211 - val_loss: 0.4139\n",
      "Epoch 50/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8141 - loss: 0.4003 - val_accuracy: 0.8153 - val_loss: 0.4134\n",
      "Epoch 51/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.8227 - loss: 0.3859 - val_accuracy: 0.8209 - val_loss: 0.4038\n",
      "Epoch 53/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8222 - loss: 0.3901 - val_accuracy: 0.8205 - val_loss: 0.4087\n",
      "Epoch 54/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8206 - loss: 0.3826 - val_accuracy: 0.8193 - val_loss: 0.4047\n",
      "Epoch 55/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8257 - loss: 0.3780 - val_accuracy: 0.8247 - val_loss: 0.3994\n",
      "Epoch 56/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8307 - loss: 0.3757 - val_accuracy: 0.8283 - val_loss: 0.4039\n",
      "Epoch 57/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8263 - loss: 0.3760 - val_accuracy: 0.8273 - val_loss: 0.3945\n",
      "Epoch 58/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8355 - loss: 0.3766 - val_accuracy: 0.8287 - val_loss: 0.4070\n",
      "Epoch 59/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8250 - loss: 0.3816 - val_accuracy: 0.8287 - val_loss: 0.3976\n",
      "Epoch 60/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8304 - loss: 0.3723 - val_accuracy: 0.8225 - val_loss: 0.4067\n",
      "Epoch 61/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8324 - loss: 0.3746 - val_accuracy: 0.8297 - val_loss: 0.3989\n",
      "Epoch 62/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8360 - loss: 0.3705 - val_accuracy: 0.8346 - val_loss: 0.3972\n",
      "Epoch 63/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 126ms/step - accuracy: 0.8312 - loss: 0.3754 - val_accuracy: 0.8281 - val_loss: 0.3972\n",
      "Epoch 64/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8304 - loss: 0.3715 - val_accuracy: 0.8155 - val_loss: 0.4116\n",
      "Epoch 65/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8388 - loss: 0.3620 - val_accuracy: 0.8261 - val_loss: 0.3924\n",
      "Epoch 66/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8340 - loss: 0.3631 - val_accuracy: 0.8326 - val_loss: 0.3927\n",
      "Epoch 67/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.8373 - loss: 0.3597 - val_accuracy: 0.8344 - val_loss: 0.3831\n",
      "Epoch 68/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8362 - loss: 0.3610 - val_accuracy: 0.8332 - val_loss: 0.3895\n",
      "Epoch 69/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.8327 - loss: 0.3641 - val_accuracy: 0.8336 - val_loss: 0.3861\n",
      "Epoch 70/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8425 - loss: 0.3556 - val_accuracy: 0.8356 - val_loss: 0.3824\n",
      "Epoch 71/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8359 - loss: 0.3631 - val_accuracy: 0.8332 - val_loss: 0.3854\n",
      "Epoch 72/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.8409 - loss: 0.3542 - val_accuracy: 0.8376 - val_loss: 0.3812\n",
      "Epoch 73/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 125ms/step - accuracy: 0.8388 - loss: 0.3542 - val_accuracy: 0.8314 - val_loss: 0.3851\n",
      "Epoch 74/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.8399 - loss: 0.3506 - val_accuracy: 0.8314 - val_loss: 0.3829\n",
      "Epoch 75/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8447 - loss: 0.3488 - val_accuracy: 0.8352 - val_loss: 0.3790\n",
      "Epoch 76/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8386 - loss: 0.3531 - val_accuracy: 0.8312 - val_loss: 0.3845\n",
      "Epoch 77/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8536 - loss: 0.3329 - val_accuracy: 0.8398 - val_loss: 0.3780\n",
      "Epoch 78/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8478 - loss: 0.3398 - val_accuracy: 0.8338 - val_loss: 0.3768\n",
      "Epoch 79/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8490 - loss: 0.3420 - val_accuracy: 0.8211 - val_loss: 0.3967\n",
      "Epoch 80/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8449 - loss: 0.3419 - val_accuracy: 0.8366 - val_loss: 0.3774\n",
      "Epoch 81/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8446 - loss: 0.3425 - val_accuracy: 0.8370 - val_loss: 0.3698\n",
      "Epoch 82/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8432 - loss: 0.3440 - val_accuracy: 0.8400 - val_loss: 0.3670\n",
      "Epoch 83/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8418 - loss: 0.3436 - val_accuracy: 0.8364 - val_loss: 0.3689\n",
      "Epoch 84/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8475 - loss: 0.3361 - val_accuracy: 0.8424 - val_loss: 0.3738\n",
      "Epoch 85/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8485 - loss: 0.3328 - val_accuracy: 0.8372 - val_loss: 0.3732\n",
      "Epoch 86/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8466 - loss: 0.3352 - val_accuracy: 0.8412 - val_loss: 0.3693\n",
      "Epoch 87/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8502 - loss: 0.3298 - val_accuracy: 0.8414 - val_loss: 0.3654\n",
      "Epoch 88/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8480 - loss: 0.3309 - val_accuracy: 0.8346 - val_loss: 0.3768\n",
      "Epoch 89/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 125ms/step - accuracy: 0.8485 - loss: 0.3363 - val_accuracy: 0.8303 - val_loss: 0.3758\n",
      "Epoch 90/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8503 - loss: 0.3337 - val_accuracy: 0.8350 - val_loss: 0.3740\n",
      "Epoch 91/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8511 - loss: 0.3293 - val_accuracy: 0.8418 - val_loss: 0.3678\n",
      "Epoch 92/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8524 - loss: 0.3253 - val_accuracy: 0.8424 - val_loss: 0.3647\n",
      "Epoch 93/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8539 - loss: 0.3242 - val_accuracy: 0.8416 - val_loss: 0.3695\n",
      "Epoch 94/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8502 - loss: 0.3312 - val_accuracy: 0.8372 - val_loss: 0.3660\n",
      "Epoch 95/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8539 - loss: 0.3232 - val_accuracy: 0.8402 - val_loss: 0.3600\n",
      "Epoch 96/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8520 - loss: 0.3183 - val_accuracy: 0.8426 - val_loss: 0.3615\n",
      "Epoch 97/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8523 - loss: 0.3257 - val_accuracy: 0.8295 - val_loss: 0.3763\n",
      "Epoch 98/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8509 - loss: 0.3246 - val_accuracy: 0.8398 - val_loss: 0.3637\n",
      "Epoch 100/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8577 - loss: 0.3183 - val_accuracy: 0.8372 - val_loss: 0.3662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 512ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>SN</th>\n",
       "      <th>SP</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.902365</td>\n",
       "      <td>0.842434</td>\n",
       "      <td>0.739229</td>\n",
       "      <td>0.816113</td>\n",
       "      <td>0.917587</td>\n",
       "      <td>0.857075</td>\n",
       "      <td>0.95273</td>\n",
       "      <td>0.939776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ACC        SN        SP       MCC  Precision       NPV        F1  \\\n",
       "0  0.8686  0.902365  0.842434  0.739229   0.816113  0.917587  0.857075   \n",
       "\n",
       "       AUC     AUPRC  \n",
       "0  0.95273  0.939776  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== FOLD 2 ===========\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/knlp/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5184 - loss: 1.5236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 143ms/step - accuracy: 0.5184 - loss: 1.5229 - val_accuracy: 0.6184 - val_loss: 0.6547\n",
      "Epoch 2/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.6091 - loss: 0.6670 - val_accuracy: 0.6949 - val_loss: 0.6091\n",
      "Epoch 3/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.6799 - loss: 0.6009 - val_accuracy: 0.6941 - val_loss: 0.5925\n",
      "Epoch 4/100\n",
      "\u001b[1m357/622\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 101ms/step - accuracy: 0.6947 - loss: 0.5846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 128ms/step - accuracy: 0.7406 - loss: 0.5270 - val_accuracy: 0.7428 - val_loss: 0.5322\n",
      "Epoch 9/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.7399 - loss: 0.5202 - val_accuracy: 0.7408 - val_loss: 0.5302\n",
      "Epoch 10/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7435 - loss: 0.5165 - val_accuracy: 0.7448 - val_loss: 0.5264\n",
      "Epoch 11/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.7562 - loss: 0.5046 - val_accuracy: 0.7613 - val_loss: 0.5143\n",
      "Epoch 13/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7521 - loss: 0.5032 - val_accuracy: 0.7569 - val_loss: 0.5096\n",
      "Epoch 14/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7587 - loss: 0.4980 - val_accuracy: 0.7593 - val_loss: 0.5025\n",
      "Epoch 15/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7589 - loss: 0.4913 - val_accuracy: 0.7657 - val_loss: 0.4949\n",
      "Epoch 16/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.7666 - loss: 0.4810 - val_accuracy: 0.7672 - val_loss: 0.5028\n",
      "Epoch 17/100\n",
      "\u001b[1m361/622\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 102ms/step - accuracy: 0.7732 - loss: 0.4756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.7704 - loss: 0.4776 - val_accuracy: 0.7680 - val_loss: 0.4863\n",
      "Epoch 18/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7784 - loss: 0.4760 - val_accuracy: 0.7657 - val_loss: 0.4925\n",
      "Epoch 19/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7699 - loss: 0.4761 - val_accuracy: 0.7730 - val_loss: 0.4793\n",
      "Epoch 20/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7719 - loss: 0.4769 - val_accuracy: 0.7825 - val_loss: 0.4748\n",
      "Epoch 21/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7784 - loss: 0.4619 - val_accuracy: 0.7776 - val_loss: 0.4772\n",
      "Epoch 22/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.7744 - loss: 0.4708 - val_accuracy: 0.7766 - val_loss: 0.4765\n",
      "Epoch 23/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.7788 - loss: 0.4669 - val_accuracy: 0.7810 - val_loss: 0.4692\n",
      "Epoch 24/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7887 - loss: 0.4476 - val_accuracy: 0.7792 - val_loss: 0.4768\n",
      "Epoch 25/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7845 - loss: 0.4580 - val_accuracy: 0.7895 - val_loss: 0.4628\n",
      "Epoch 26/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.7872 - loss: 0.4478 - val_accuracy: 0.7903 - val_loss: 0.4531\n",
      "Epoch 28/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7911 - loss: 0.4412 - val_accuracy: 0.7859 - val_loss: 0.4599\n",
      "Epoch 29/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7990 - loss: 0.4310 - val_accuracy: 0.7959 - val_loss: 0.4510\n",
      "Epoch 30/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7916 - loss: 0.4382 - val_accuracy: 0.7933 - val_loss: 0.4497\n",
      "Epoch 31/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8009 - loss: 0.4305 - val_accuracy: 0.7883 - val_loss: 0.4485\n",
      "Epoch 32/100\n",
      "\u001b[1m217/622\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 103ms/step - accuracy: 0.7911 - loss: 0.4366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.8007 - loss: 0.4247 - val_accuracy: 0.8026 - val_loss: 0.4435\n",
      "Epoch 35/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8008 - loss: 0.4257 - val_accuracy: 0.7947 - val_loss: 0.4417\n",
      "Epoch 36/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8069 - loss: 0.4209 - val_accuracy: 0.8054 - val_loss: 0.4389\n",
      "Epoch 37/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8080 - loss: 0.4142 - val_accuracy: 0.7957 - val_loss: 0.4395\n",
      "Epoch 38/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8102 - loss: 0.4133 - val_accuracy: 0.8094 - val_loss: 0.4251\n",
      "Epoch 39/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8048 - loss: 0.4178 - val_accuracy: 0.8066 - val_loss: 0.4261\n",
      "Epoch 40/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8109 - loss: 0.4128 - val_accuracy: 0.8098 - val_loss: 0.4278\n",
      "Epoch 41/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8082 - loss: 0.4165 - val_accuracy: 0.8054 - val_loss: 0.4244\n",
      "Epoch 42/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8061 - loss: 0.4136 - val_accuracy: 0.8048 - val_loss: 0.4253\n",
      "Epoch 43/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8149 - loss: 0.4046 - val_accuracy: 0.8094 - val_loss: 0.4192\n",
      "Epoch 44/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8137 - loss: 0.4006 - val_accuracy: 0.8108 - val_loss: 0.4164\n",
      "Epoch 45/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8147 - loss: 0.4017 - val_accuracy: 0.8153 - val_loss: 0.4134\n",
      "Epoch 46/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8142 - loss: 0.4048 - val_accuracy: 0.8130 - val_loss: 0.4111\n",
      "Epoch 47/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8217 - loss: 0.3965 - val_accuracy: 0.8132 - val_loss: 0.4097\n",
      "Epoch 48/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8183 - loss: 0.3984 - val_accuracy: 0.8128 - val_loss: 0.4139\n",
      "Epoch 49/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8239 - loss: 0.3890 - val_accuracy: 0.8157 - val_loss: 0.4026\n",
      "Epoch 50/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8199 - loss: 0.3934 - val_accuracy: 0.8157 - val_loss: 0.4099\n",
      "Epoch 51/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8211 - loss: 0.3921 - val_accuracy: 0.8163 - val_loss: 0.4020\n",
      "Epoch 52/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8179 - loss: 0.3898 - val_accuracy: 0.8239 - val_loss: 0.3998\n",
      "Epoch 53/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8243 - loss: 0.3848 - val_accuracy: 0.8201 - val_loss: 0.4029\n",
      "Epoch 54/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8242 - loss: 0.3844 - val_accuracy: 0.8225 - val_loss: 0.4027\n",
      "Epoch 55/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8239 - loss: 0.3802 - val_accuracy: 0.8241 - val_loss: 0.3982\n",
      "Epoch 56/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8247 - loss: 0.3803 - val_accuracy: 0.8259 - val_loss: 0.4010\n",
      "Epoch 57/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8304 - loss: 0.3754 - val_accuracy: 0.8259 - val_loss: 0.3928\n",
      "Epoch 58/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8278 - loss: 0.3754 - val_accuracy: 0.8235 - val_loss: 0.3953\n",
      "Epoch 59/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 126ms/step - accuracy: 0.8273 - loss: 0.3780 - val_accuracy: 0.8295 - val_loss: 0.3946\n",
      "Epoch 60/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8273 - loss: 0.3740 - val_accuracy: 0.8237 - val_loss: 0.3964\n",
      "Epoch 61/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8240 - loss: 0.3823 - val_accuracy: 0.8285 - val_loss: 0.3895\n",
      "Epoch 62/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8345 - loss: 0.3646 - val_accuracy: 0.8233 - val_loss: 0.3939\n",
      "Epoch 63/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8326 - loss: 0.3677 - val_accuracy: 0.8291 - val_loss: 0.3882\n",
      "Epoch 64/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 124ms/step - accuracy: 0.8354 - loss: 0.3682 - val_accuracy: 0.8279 - val_loss: 0.3898\n",
      "Epoch 65/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8369 - loss: 0.3596 - val_accuracy: 0.8285 - val_loss: 0.3897\n",
      "Epoch 66/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 125ms/step - accuracy: 0.8335 - loss: 0.3625 - val_accuracy: 0.8320 - val_loss: 0.3923\n",
      "Epoch 67/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.8328 - loss: 0.3690 - val_accuracy: 0.8295 - val_loss: 0.3839\n",
      "Epoch 68/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8311 - loss: 0.3613 - val_accuracy: 0.8342 - val_loss: 0.3815\n",
      "Epoch 69/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8335 - loss: 0.3626 - val_accuracy: 0.8253 - val_loss: 0.3902\n",
      "Epoch 70/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.8294 - loss: 0.3700 - val_accuracy: 0.8303 - val_loss: 0.3823\n",
      "Epoch 71/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8377 - loss: 0.3593 - val_accuracy: 0.8277 - val_loss: 0.3843\n",
      "Epoch 72/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.8357 - loss: 0.3638 - val_accuracy: 0.8330 - val_loss: 0.3779\n",
      "Epoch 73/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8436 - loss: 0.3506 - val_accuracy: 0.8316 - val_loss: 0.3816\n",
      "Epoch 74/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8348 - loss: 0.3555 - val_accuracy: 0.8334 - val_loss: 0.3788\n",
      "Epoch 75/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8420 - loss: 0.3485 - val_accuracy: 0.8392 - val_loss: 0.3766\n",
      "Epoch 76/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8404 - loss: 0.3501 - val_accuracy: 0.8324 - val_loss: 0.3800\n",
      "Epoch 77/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8464 - loss: 0.3467 - val_accuracy: 0.8350 - val_loss: 0.3720\n",
      "Epoch 78/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8411 - loss: 0.3477 - val_accuracy: 0.8370 - val_loss: 0.3721\n",
      "Epoch 79/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8435 - loss: 0.3455 - val_accuracy: 0.8314 - val_loss: 0.3777\n",
      "Epoch 80/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8416 - loss: 0.3447 - val_accuracy: 0.8301 - val_loss: 0.3768\n",
      "Epoch 81/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8449 - loss: 0.3411 - val_accuracy: 0.8398 - val_loss: 0.3705\n",
      "Epoch 82/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8453 - loss: 0.3432 - val_accuracy: 0.8386 - val_loss: 0.3685\n",
      "Epoch 83/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8480 - loss: 0.3456 - val_accuracy: 0.8392 - val_loss: 0.3665\n",
      "Epoch 85/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8488 - loss: 0.3296 - val_accuracy: 0.8388 - val_loss: 0.3664\n",
      "Epoch 86/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8484 - loss: 0.3317 - val_accuracy: 0.8422 - val_loss: 0.3662\n",
      "Epoch 87/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8442 - loss: 0.3413 - val_accuracy: 0.8376 - val_loss: 0.3686\n",
      "Epoch 88/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8477 - loss: 0.3343 - val_accuracy: 0.8336 - val_loss: 0.3747\n",
      "Epoch 89/100\n",
      "\u001b[1m318/622\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - accuracy: 0.8454 - loss: 0.3379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7369 - loss: 0.5186 - val_accuracy: 0.7593 - val_loss: 0.5098\n",
      "Epoch 13/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7577 - loss: 0.4981 - val_accuracy: 0.7631 - val_loss: 0.4968\n",
      "Epoch 14/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7577 - loss: 0.5017 - val_accuracy: 0.7706 - val_loss: 0.4980\n",
      "Epoch 15/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7581 - loss: 0.4928 - val_accuracy: 0.7692 - val_loss: 0.4869\n",
      "Epoch 16/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.7642 - loss: 0.4923 - val_accuracy: 0.7712 - val_loss: 0.4902\n",
      "Epoch 17/100\n",
      "\u001b[1m223/622\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 100ms/step - accuracy: 0.7726 - loss: 0.4854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 128ms/step - accuracy: 0.8107 - loss: 0.4077 - val_accuracy: 0.8116 - val_loss: 0.4093\n",
      "Epoch 41/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8127 - loss: 0.4086 - val_accuracy: 0.8151 - val_loss: 0.4137\n",
      "Epoch 42/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.8141 - loss: 0.4040 - val_accuracy: 0.8157 - val_loss: 0.4128\n",
      "Epoch 43/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.8096 - loss: 0.4119 - val_accuracy: 0.8177 - val_loss: 0.4072\n",
      "Epoch 44/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8130 - loss: 0.4086 - val_accuracy: 0.8191 - val_loss: 0.4016\n",
      "Epoch 45/100\n",
      "\u001b[1m307/622\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 102ms/step - accuracy: 0.8144 - loss: 0.4051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 126ms/step - accuracy: 0.8414 - loss: 0.3551 - val_accuracy: 0.8344 - val_loss: 0.3679\n",
      "Epoch 68/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.8422 - loss: 0.3566 - val_accuracy: 0.8374 - val_loss: 0.3636\n",
      "Epoch 69/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.8450 - loss: 0.3488 - val_accuracy: 0.8372 - val_loss: 0.3672\n",
      "Epoch 70/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 134ms/step - accuracy: 0.8392 - loss: 0.3550 - val_accuracy: 0.8368 - val_loss: 0.3638\n",
      "Epoch 71/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8419 - loss: 0.3573 - val_accuracy: 0.8334 - val_loss: 0.3662\n",
      "Epoch 72/100\n",
      "\u001b[1m255/622\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 112ms/step - accuracy: 0.8464 - loss: 0.3407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 128ms/step - accuracy: 0.8598 - loss: 0.3158 - val_accuracy: 0.8370 - val_loss: 0.3542\n",
      "Epoch 96/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8655 - loss: 0.3084 - val_accuracy: 0.8422 - val_loss: 0.3440\n",
      "Epoch 97/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8611 - loss: 0.3132 - val_accuracy: 0.8448 - val_loss: 0.3471\n",
      "Epoch 98/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8625 - loss: 0.3133 - val_accuracy: 0.8418 - val_loss: 0.3427\n",
      "Epoch 99/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 126ms/step - accuracy: 0.8566 - loss: 0.3125 - val_accuracy: 0.8418 - val_loss: 0.3455\n",
      "Epoch 100/100\n",
      "\u001b[1m281/622\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 102ms/step - accuracy: 0.8645 - loss: 0.3009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7748 - loss: 0.4705 - val_accuracy: 0.7880 - val_loss: 0.4749\n",
      "Epoch 23/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7746 - loss: 0.4676 - val_accuracy: 0.7888 - val_loss: 0.4669\n",
      "Epoch 24/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7877 - loss: 0.4538 - val_accuracy: 0.7977 - val_loss: 0.4714\n",
      "Epoch 25/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 133ms/step - accuracy: 0.7817 - loss: 0.4540 - val_accuracy: 0.7895 - val_loss: 0.4652\n",
      "Epoch 26/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7872 - loss: 0.4478 - val_accuracy: 0.7995 - val_loss: 0.4664\n",
      "Epoch 27/100\n",
      "\u001b[1m359/622\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7809 - loss: 0.4567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8185 - loss: 0.3947 - val_accuracy: 0.8249 - val_loss: 0.3998\n",
      "Epoch 50/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.8214 - loss: 0.3936 - val_accuracy: 0.8295 - val_loss: 0.3976\n",
      "Epoch 51/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8257 - loss: 0.3839 - val_accuracy: 0.8313 - val_loss: 0.3942\n",
      "Epoch 52/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 134ms/step - accuracy: 0.8207 - loss: 0.3839 - val_accuracy: 0.8253 - val_loss: 0.4054\n",
      "Epoch 53/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 134ms/step - accuracy: 0.8243 - loss: 0.3873 - val_accuracy: 0.8227 - val_loss: 0.3948\n",
      "Epoch 54/100\n",
      "\u001b[1m459/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 99ms/step - accuracy: 0.8170 - loss: 0.3943"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 153ms/step - accuracy: 0.8355 - loss: 0.3583 - val_accuracy: 0.8426 - val_loss: 0.3689\n",
      "Epoch 69/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.8344 - loss: 0.3724 - val_accuracy: 0.8432 - val_loss: 0.3653\n",
      "Epoch 70/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8418 - loss: 0.3522 - val_accuracy: 0.8394 - val_loss: 0.3720\n",
      "Epoch 71/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8416 - loss: 0.3542 - val_accuracy: 0.8380 - val_loss: 0.3719\n",
      "Epoch 72/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8387 - loss: 0.3521 - val_accuracy: 0.8462 - val_loss: 0.3682\n",
      "Epoch 73/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8393 - loss: 0.3522 - val_accuracy: 0.8480 - val_loss: 0.3601\n",
      "Epoch 74/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8392 - loss: 0.3502 - val_accuracy: 0.8478 - val_loss: 0.3657\n",
      "Epoch 75/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 121ms/step - accuracy: 0.8449 - loss: 0.3419 - val_accuracy: 0.8500 - val_loss: 0.3622\n",
      "Epoch 76/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8442 - loss: 0.3458 - val_accuracy: 0.8428 - val_loss: 0.3602\n",
      "Epoch 77/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8439 - loss: 0.3487 - val_accuracy: 0.8468 - val_loss: 0.3562\n",
      "Epoch 78/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8461 - loss: 0.3379 - val_accuracy: 0.8508 - val_loss: 0.3589\n",
      "Epoch 79/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8473 - loss: 0.3386 - val_accuracy: 0.8265 - val_loss: 0.3804\n",
      "Epoch 80/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8428 - loss: 0.3450 - val_accuracy: 0.8486 - val_loss: 0.3541\n",
      "Epoch 81/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8423 - loss: 0.3438 - val_accuracy: 0.8440 - val_loss: 0.3551\n",
      "Epoch 82/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8461 - loss: 0.3402 - val_accuracy: 0.8482 - val_loss: 0.3511\n",
      "Epoch 83/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8459 - loss: 0.3367 - val_accuracy: 0.8444 - val_loss: 0.3548\n",
      "Epoch 84/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8554 - loss: 0.3279 - val_accuracy: 0.8476 - val_loss: 0.3514\n",
      "Epoch 85/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8495 - loss: 0.3382 - val_accuracy: 0.8454 - val_loss: 0.3544\n",
      "Epoch 86/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.8513 - loss: 0.3311 - val_accuracy: 0.8472 - val_loss: 0.3560\n",
      "Epoch 87/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8559 - loss: 0.3235 - val_accuracy: 0.8488 - val_loss: 0.3594\n",
      "Epoch 88/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8468 - loss: 0.3365 - val_accuracy: 0.8478 - val_loss: 0.3484\n",
      "Epoch 89/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8524 - loss: 0.3302 - val_accuracy: 0.8498 - val_loss: 0.3497\n",
      "Epoch 90/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8498 - loss: 0.3237 - val_accuracy: 0.8464 - val_loss: 0.3545\n",
      "Epoch 91/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8523 - loss: 0.3293 - val_accuracy: 0.8460 - val_loss: 0.3588\n",
      "Epoch 92/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8542 - loss: 0.3263 - val_accuracy: 0.8492 - val_loss: 0.3483\n",
      "Epoch 93/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8543 - loss: 0.3254 - val_accuracy: 0.8512 - val_loss: 0.3451\n",
      "Epoch 94/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8561 - loss: 0.3168 - val_accuracy: 0.8537 - val_loss: 0.3408\n",
      "Epoch 95/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8558 - loss: 0.3199 - val_accuracy: 0.8519 - val_loss: 0.3426\n",
      "Epoch 96/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8574 - loss: 0.3229 - val_accuracy: 0.8468 - val_loss: 0.3543\n",
      "Epoch 97/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8583 - loss: 0.3174 - val_accuracy: 0.8514 - val_loss: 0.3412\n",
      "Epoch 98/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8678 - loss: 0.3099 - val_accuracy: 0.8529 - val_loss: 0.3453\n",
      "Epoch 99/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8610 - loss: 0.3184 - val_accuracy: 0.8470 - val_loss: 0.3508\n",
      "Epoch 100/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 121ms/step - accuracy: 0.8600 - loss: 0.3106 - val_accuracy: 0.8527 - val_loss: 0.3481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 97ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>SN</th>\n",
       "      <th>SP</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.872555</td>\n",
       "      <td>0.874182</td>\n",
       "      <td>0.871295</td>\n",
       "      <td>0.742585</td>\n",
       "      <td>0.840348</td>\n",
       "      <td>0.899356</td>\n",
       "      <td>0.856931</td>\n",
       "      <td>0.950831</td>\n",
       "      <td>0.938654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC        SN        SP       MCC  Precision       NPV        F1  \\\n",
       "0  0.872555  0.874182  0.871295  0.742585   0.840348  0.899356  0.856931   \n",
       "\n",
       "        AUC     AUPRC  \n",
       "0  0.950831  0.938654  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== FOLD 5 ===========\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/knlp/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5182 - loss: 1.5910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 138ms/step - accuracy: 0.5182 - loss: 1.5902 - val_accuracy: 0.6995 - val_loss: 0.6446\n",
      "Epoch 2/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.6077 - loss: 0.6633 - val_accuracy: 0.7156 - val_loss: 0.6040\n",
      "Epoch 3/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.6712 - loss: 0.6077 - val_accuracy: 0.7381 - val_loss: 0.5762\n",
      "Epoch 4/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7008 - loss: 0.5772 - val_accuracy: 0.7470 - val_loss: 0.5548\n",
      "Epoch 5/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.7178 - loss: 0.5636 - val_accuracy: 0.7510 - val_loss: 0.5498\n",
      "Epoch 6/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.7205 - loss: 0.5472 - val_accuracy: 0.7564 - val_loss: 0.5424\n",
      "Epoch 7/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 121ms/step - accuracy: 0.7349 - loss: 0.5347 - val_accuracy: 0.7522 - val_loss: 0.5321\n",
      "Epoch 8/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.7299 - loss: 0.5348 - val_accuracy: 0.7607 - val_loss: 0.5206\n",
      "Epoch 9/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7403 - loss: 0.5240 - val_accuracy: 0.7655 - val_loss: 0.5220\n",
      "Epoch 10/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7393 - loss: 0.5200 - val_accuracy: 0.7661 - val_loss: 0.5176\n",
      "Epoch 11/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7545 - loss: 0.5070 - val_accuracy: 0.7687 - val_loss: 0.5022\n",
      "Epoch 12/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.7440 - loss: 0.5107 - val_accuracy: 0.7723 - val_loss: 0.5033\n",
      "Epoch 13/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7554 - loss: 0.5013 - val_accuracy: 0.7770 - val_loss: 0.5042\n",
      "Epoch 14/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7618 - loss: 0.4960 - val_accuracy: 0.7814 - val_loss: 0.5110\n",
      "Epoch 15/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7560 - loss: 0.4968 - val_accuracy: 0.7754 - val_loss: 0.4970\n",
      "Epoch 16/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7610 - loss: 0.4924 - val_accuracy: 0.7788 - val_loss: 0.4908\n",
      "Epoch 17/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7657 - loss: 0.4849 - val_accuracy: 0.7794 - val_loss: 0.4810\n",
      "Epoch 18/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.7731 - loss: 0.4791 - val_accuracy: 0.7810 - val_loss: 0.4850\n",
      "Epoch 19/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7699 - loss: 0.4722 - val_accuracy: 0.7830 - val_loss: 0.4769\n",
      "Epoch 20/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7712 - loss: 0.4803 - val_accuracy: 0.7834 - val_loss: 0.4826\n",
      "Epoch 21/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7739 - loss: 0.4711 - val_accuracy: 0.7840 - val_loss: 0.4720\n",
      "Epoch 23/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.7755 - loss: 0.4687 - val_accuracy: 0.7880 - val_loss: 0.4684\n",
      "Epoch 24/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7845 - loss: 0.4553 - val_accuracy: 0.7909 - val_loss: 0.4757\n",
      "Epoch 25/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7812 - loss: 0.4564 - val_accuracy: 0.7929 - val_loss: 0.4567\n",
      "Epoch 26/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.7798 - loss: 0.4614 - val_accuracy: 0.7939 - val_loss: 0.4661\n",
      "Epoch 27/100\n",
      "\u001b[1m507/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.7879 - loss: 0.4506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 127ms/step - accuracy: 0.8257 - loss: 0.3822 - val_accuracy: 0.8279 - val_loss: 0.4054\n",
      "Epoch 51/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8236 - loss: 0.3900 - val_accuracy: 0.8273 - val_loss: 0.3958\n",
      "Epoch 52/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.8277 - loss: 0.3873 - val_accuracy: 0.8237 - val_loss: 0.3983\n",
      "Epoch 53/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8269 - loss: 0.3841 - val_accuracy: 0.8283 - val_loss: 0.3979\n",
      "Epoch 54/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8316 - loss: 0.3764 - val_accuracy: 0.8287 - val_loss: 0.3957\n",
      "Epoch 55/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8214 - loss: 0.3917 - val_accuracy: 0.8331 - val_loss: 0.3879\n",
      "Epoch 56/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8345 - loss: 0.3687 - val_accuracy: 0.8335 - val_loss: 0.3890\n",
      "Epoch 57/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 121ms/step - accuracy: 0.8287 - loss: 0.3742 - val_accuracy: 0.8287 - val_loss: 0.3887\n",
      "Epoch 58/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8241 - loss: 0.3769 - val_accuracy: 0.8251 - val_loss: 0.4002\n",
      "Epoch 59/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.8283 - loss: 0.3767 - val_accuracy: 0.8239 - val_loss: 0.3931\n",
      "Epoch 60/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8325 - loss: 0.3744 - val_accuracy: 0.8257 - val_loss: 0.3899\n",
      "Epoch 61/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 125ms/step - accuracy: 0.8351 - loss: 0.3716 - val_accuracy: 0.8366 - val_loss: 0.3825\n",
      "Epoch 62/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8310 - loss: 0.3717 - val_accuracy: 0.8295 - val_loss: 0.3848\n",
      "Epoch 63/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8410 - loss: 0.3624 - val_accuracy: 0.8305 - val_loss: 0.3846\n",
      "Epoch 64/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8367 - loss: 0.3675 - val_accuracy: 0.8392 - val_loss: 0.3771\n",
      "Epoch 65/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8311 - loss: 0.3709 - val_accuracy: 0.8211 - val_loss: 0.3871\n",
      "Epoch 66/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.8399 - loss: 0.3608 - val_accuracy: 0.8353 - val_loss: 0.3775\n",
      "Epoch 67/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8421 - loss: 0.3535 - val_accuracy: 0.8372 - val_loss: 0.3763\n",
      "Epoch 68/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8387 - loss: 0.3610 - val_accuracy: 0.8386 - val_loss: 0.3762\n",
      "Epoch 70/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8413 - loss: 0.3532 - val_accuracy: 0.8341 - val_loss: 0.3764\n",
      "Epoch 71/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8401 - loss: 0.3615 - val_accuracy: 0.8241 - val_loss: 0.3876\n",
      "Epoch 72/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8462 - loss: 0.3505 - val_accuracy: 0.8335 - val_loss: 0.3779\n",
      "Epoch 73/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.8438 - loss: 0.3505 - val_accuracy: 0.8448 - val_loss: 0.3681\n",
      "Epoch 74/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 126ms/step - accuracy: 0.8453 - loss: 0.3510 - val_accuracy: 0.8434 - val_loss: 0.3718\n",
      "Epoch 75/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8465 - loss: 0.3396 - val_accuracy: 0.8414 - val_loss: 0.3744\n",
      "Epoch 76/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8444 - loss: 0.3492 - val_accuracy: 0.8291 - val_loss: 0.3825\n",
      "Epoch 77/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8445 - loss: 0.3546 - val_accuracy: 0.8392 - val_loss: 0.3659\n",
      "Epoch 78/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8420 - loss: 0.3521 - val_accuracy: 0.8456 - val_loss: 0.3610\n",
      "Epoch 79/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8469 - loss: 0.3472 - val_accuracy: 0.8422 - val_loss: 0.3604\n",
      "Epoch 80/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8451 - loss: 0.3435 - val_accuracy: 0.8400 - val_loss: 0.3631\n",
      "Epoch 81/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8461 - loss: 0.3401 - val_accuracy: 0.8432 - val_loss: 0.3632\n",
      "Epoch 83/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.8471 - loss: 0.3444 - val_accuracy: 0.8345 - val_loss: 0.3683\n",
      "Epoch 84/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 123ms/step - accuracy: 0.8404 - loss: 0.3501 - val_accuracy: 0.8355 - val_loss: 0.3675\n",
      "Epoch 85/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8482 - loss: 0.3375 - val_accuracy: 0.8418 - val_loss: 0.3555\n",
      "Epoch 86/100\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.8578 - loss: 0.3270 - val_accuracy: 0.8464 - val_loss: 0.3554\n",
      "Epoch 87/100\n",
      "\u001b[1m367/622\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.8514 - loss: 0.3339"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, f1_score, roc_auc_score,\n",
    "    average_precision_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# Setup\n",
    "# ================================================================\n",
    "train_df,unseen_df = df[df['split']=='seen'].copy(),  df[df['split']=='unseen'].copy()\n",
    "\n",
    "X = train_df.index.values  # DataSequenceLoader loads using df, so features = df itself\n",
    "y = train_df['label'].values\n",
    "bs =32\n",
    "unseen_loader  = DataSequenceLoader(unseen_df, batch_size=bs, shuffle=False)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 5-Fold Training Loop\n",
    "# ================================================================\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    WEIGHT_PATH = f\"../weights/LlamaCrossAttn_HIV-RLEAAI/model_fold_{fold}.weights.h5\"\n",
    "    os.makedirs(os.path.dirname(WEIGHT_PATH),exist_ok=True)\n",
    "    print(f\"\\n=========== FOLD {fold+1} ===========\")\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df  = df.iloc[test_idx]\n",
    "    bs =32\n",
    "    # ---- Loaders ----\n",
    "    train_loader = DataSequenceLoader(train_df, batch_size=bs, shuffle=True)\n",
    "    test_loader  = DataSequenceLoader(test_df, batch_size=bs, shuffle=False)\n",
    "\n",
    "    # ---- Build Model ----\n",
    "    model = build_model()\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # ---- Train ----\n",
    "    model.fit(train_loader,  validation_data=test_loader, epochs=100, verbose=1)\n",
    "\n",
    "    model.save_weights(WEIGHT_PATH)\n",
    "    # ---- Predict ----\n",
    "    y_true =unseen_df['label'].values\n",
    "    y_prob = model.predict(unseen_loader)\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "    # ---- Confusion Matrix ----\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # ---- Metrics ----\n",
    "    ACC  = accuracy_score(y_true, y_pred)\n",
    "    SN   = recall_score(y_true, y_pred)\n",
    "    SP   = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    MCC  = matthews_corrcoef(y_true, y_pred)\n",
    "    PREC = precision_score(y_true, y_pred)\n",
    "    NPV  = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    F1   = f1_score(y_true, y_pred)\n",
    "    AUC  = roc_auc_score(y_true, y_prob)\n",
    "    AUPR = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    fold_metrics = {\n",
    "        \"ACC\": ACC,\n",
    "        \"SN\": SN,\n",
    "        \"SP\": SP,\n",
    "        \"MCC\": MCC,\n",
    "        \"Precision\": PREC,\n",
    "        \"NPV\": NPV,\n",
    "        \"F1\": F1,\n",
    "        \"AUC\": AUC,\n",
    "        \"AUPRC\": AUPR\n",
    "    }\n",
    "\n",
    "    fold_results.append(fold_metrics)\n",
    "\n",
    "    # ---- Print fold results ----\n",
    "    display(pd.DataFrame([fold_metrics]))\n",
    "\n",
    "    # ---- Cleanup model + loaders ----\n",
    "    del model\n",
    "    del train_loader\n",
    "    del test_loader\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# Final results: per fold + mean\n",
    "# ================================================================\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\n=========== FINAL 5-FOLD RESULTS ===========\")\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\n=========== MEAN METRICS ===========\")\n",
    "display(results_df.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a2f0446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== FOLD 1 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764881659.861414  118629 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79078 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "/home/mhossai5/.conda/envs/knlp/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764881663.937401  118956 service.cc:148] XLA service 0x7ffe740029d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1764881663.937476  118956 service.cc:156]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "I0000 00:00:1764881664.370173  118956 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  3/143\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 61ms/step    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764881712.840687  118956 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 533ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>SN</th>\n",
       "      <th>SP</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.902365</td>\n",
       "      <td>0.842434</td>\n",
       "      <td>0.739229</td>\n",
       "      <td>0.816113</td>\n",
       "      <td>0.917587</td>\n",
       "      <td>0.857075</td>\n",
       "      <td>0.95273</td>\n",
       "      <td>0.939776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ACC        SN        SP       MCC  Precision       NPV        F1  \\\n",
       "0  0.8686  0.902365  0.842434  0.739229   0.816113  0.917587  0.857075   \n",
       "\n",
       "       AUC     AUPRC  \n",
       "0  0.95273  0.939776  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== FOLD 2 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 104ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>SN</th>\n",
       "      <th>SP</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.878488</td>\n",
       "      <td>0.821842</td>\n",
       "      <td>0.922387</td>\n",
       "      <td>0.752657</td>\n",
       "      <td>0.891376</td>\n",
       "      <td>0.869805</td>\n",
       "      <td>0.855198</td>\n",
       "      <td>0.953557</td>\n",
       "      <td>0.940023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC        SN        SP       MCC  Precision       NPV        F1  \\\n",
       "0  0.878488  0.821842  0.922387  0.752657   0.891376  0.869805  0.855198   \n",
       "\n",
       "        AUC     AUPRC  \n",
       "0  0.953557  0.940023  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== FOLD 3 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>SN</th>\n",
       "      <th>SP</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.878488</td>\n",
       "      <td>0.858078</td>\n",
       "      <td>0.894306</td>\n",
       "      <td>0.752861</td>\n",
       "      <td>0.862854</td>\n",
       "      <td>0.890485</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>0.9429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC        SN        SP       MCC  Precision       NPV        F1  \\\n",
       "0  0.878488  0.858078  0.894306  0.752861   0.862854  0.890485  0.860459   \n",
       "\n",
       "        AUC   AUPRC  \n",
       "0  0.955961  0.9429  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== FOLD 4 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 99ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>SN</th>\n",
       "      <th>SP</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.872555</td>\n",
       "      <td>0.874182</td>\n",
       "      <td>0.871295</td>\n",
       "      <td>0.742585</td>\n",
       "      <td>0.840348</td>\n",
       "      <td>0.899356</td>\n",
       "      <td>0.856931</td>\n",
       "      <td>0.950831</td>\n",
       "      <td>0.938654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC        SN        SP       MCC  Precision       NPV        F1  \\\n",
       "0  0.872555  0.874182  0.871295  0.742585   0.840348  0.899356  0.856931   \n",
       "\n",
       "        AUC     AUPRC  \n",
       "0  0.950831  0.938654  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== FOLD 5 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 99ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>SN</th>\n",
       "      <th>SP</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.874533</td>\n",
       "      <td>0.860594</td>\n",
       "      <td>0.885335</td>\n",
       "      <td>0.745233</td>\n",
       "      <td>0.853293</td>\n",
       "      <td>0.891245</td>\n",
       "      <td>0.856928</td>\n",
       "      <td>0.951662</td>\n",
       "      <td>0.937467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC        SN        SP       MCC  Precision       NPV        F1  \\\n",
       "0  0.874533  0.860594  0.885335  0.745233   0.853293  0.891245  0.856928   \n",
       "\n",
       "        AUC     AUPRC  \n",
       "0  0.951662  0.937467  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== FINAL 5-FOLD RESULTS ===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>SN</th>\n",
       "      <th>SP</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868600</td>\n",
       "      <td>0.902365</td>\n",
       "      <td>0.842434</td>\n",
       "      <td>0.739229</td>\n",
       "      <td>0.816113</td>\n",
       "      <td>0.917587</td>\n",
       "      <td>0.857075</td>\n",
       "      <td>0.952730</td>\n",
       "      <td>0.939776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.878488</td>\n",
       "      <td>0.821842</td>\n",
       "      <td>0.922387</td>\n",
       "      <td>0.752657</td>\n",
       "      <td>0.891376</td>\n",
       "      <td>0.869805</td>\n",
       "      <td>0.855198</td>\n",
       "      <td>0.953557</td>\n",
       "      <td>0.940023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878488</td>\n",
       "      <td>0.858078</td>\n",
       "      <td>0.894306</td>\n",
       "      <td>0.752861</td>\n",
       "      <td>0.862854</td>\n",
       "      <td>0.890485</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>0.942900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.872555</td>\n",
       "      <td>0.874182</td>\n",
       "      <td>0.871295</td>\n",
       "      <td>0.742585</td>\n",
       "      <td>0.840348</td>\n",
       "      <td>0.899356</td>\n",
       "      <td>0.856931</td>\n",
       "      <td>0.950831</td>\n",
       "      <td>0.938654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.874533</td>\n",
       "      <td>0.860594</td>\n",
       "      <td>0.885335</td>\n",
       "      <td>0.745233</td>\n",
       "      <td>0.853293</td>\n",
       "      <td>0.891245</td>\n",
       "      <td>0.856928</td>\n",
       "      <td>0.951662</td>\n",
       "      <td>0.937467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC        SN        SP       MCC  Precision       NPV        F1  \\\n",
       "0  0.868600  0.902365  0.842434  0.739229   0.816113  0.917587  0.857075   \n",
       "1  0.878488  0.821842  0.922387  0.752657   0.891376  0.869805  0.855198   \n",
       "2  0.878488  0.858078  0.894306  0.752861   0.862854  0.890485  0.860459   \n",
       "3  0.872555  0.874182  0.871295  0.742585   0.840348  0.899356  0.856931   \n",
       "4  0.874533  0.860594  0.885335  0.745233   0.853293  0.891245  0.856928   \n",
       "\n",
       "        AUC     AUPRC  \n",
       "0  0.952730  0.939776  \n",
       "1  0.953557  0.940023  \n",
       "2  0.955961  0.942900  \n",
       "3  0.950831  0.938654  \n",
       "4  0.951662  0.937467  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== MEAN METRICS ===========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ACC          0.874533\n",
       "SN           0.863412\n",
       "SP           0.883151\n",
       "MCC          0.746513\n",
       "Precision    0.852797\n",
       "NPV          0.893696\n",
       "F1           0.857318\n",
       "AUC          0.952948\n",
       "AUPRC        0.939764\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, f1_score, roc_auc_score,\n",
    "    average_precision_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# Setup\n",
    "# ================================================================\n",
    "train_df,unseen_df = df[df['split']=='seen'].copy(),  df[df['split']=='unseen'].copy()\n",
    "\n",
    "X = train_df.index.values  # DataSequenceLoader loads using df, so features = df itself\n",
    "y = train_df['label'].values\n",
    "bs =32\n",
    "unseen_loader  = DataSequenceLoader(unseen_df, batch_size=bs, shuffle=False)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 5-Fold Training Loop\n",
    "# ================================================================\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    WEIGHT_PATH = f\"../weights/LlamaCrossAttn_HIV-RLEAAI/model_fold_{fold}.weights.h5\"\n",
    "    os.makedirs(os.path.dirname(WEIGHT_PATH),exist_ok=True)\n",
    "    print(f\"\\n=========== FOLD {fold+1} ===========\")\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df  = df.iloc[test_idx]\n",
    "    bs =32\n",
    "    # ---- Loaders ----\n",
    "    train_loader = DataSequenceLoader(train_df, batch_size=bs, shuffle=True)\n",
    "    test_loader  = DataSequenceLoader(test_df, batch_size=bs, shuffle=False)\n",
    "\n",
    "    # ---- Build Model ----\n",
    "    model = build_model()\n",
    "    model.load_weights(WEIGHT_PATH)\n",
    "    # ---- Predict ----\n",
    "    y_true =unseen_df['label'].values\n",
    "    y_prob = model.predict(unseen_loader)\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "    # ---- Confusion Matrix ----\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # ---- Metrics ----\n",
    "    ACC  = accuracy_score(y_true, y_pred)\n",
    "    SN   = recall_score(y_true, y_pred)\n",
    "    SP   = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    MCC  = matthews_corrcoef(y_true, y_pred)\n",
    "    PREC = precision_score(y_true, y_pred)\n",
    "    NPV  = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    F1   = f1_score(y_true, y_pred)\n",
    "    AUC  = roc_auc_score(y_true, y_prob)\n",
    "    AUPR = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    fold_metrics = {\n",
    "        \"ACC\": ACC,\n",
    "        \"SN\": SN,\n",
    "        \"SP\": SP,\n",
    "        \"MCC\": MCC,\n",
    "        \"Precision\": PREC,\n",
    "        \"NPV\": NPV,\n",
    "        \"F1\": F1,\n",
    "        \"AUC\": AUC,\n",
    "        \"AUPRC\": AUPR\n",
    "    }\n",
    "\n",
    "    fold_results.append(fold_metrics)\n",
    "\n",
    "    # ---- Print fold results ----\n",
    "    display(pd.DataFrame([fold_metrics]))\n",
    "\n",
    "    # ---- Cleanup model + loaders ----\n",
    "    del model\n",
    "    del train_loader\n",
    "    del test_loader\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# Final results: per fold + mean\n",
    "# ================================================================\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\n=========== FINAL 5-FOLD RESULTS ===========\")\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\n=========== MEAN METRICS ===========\")\n",
    "display(results_df.mean())\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-knlp]",
   "language": "python",
   "name": "conda-env-.conda-knlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
