{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efac3282-17b1-45e0-ae4a-1034adcf63c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-01-04 06:46:20.206045: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767530780.220261   63792 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767530780.225205   63792 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767530780.239214   63792 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767530780.239225   63792 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767530780.239227   63792 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767530780.239229   63792 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] ='tensorflow'\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from keras import layers, Model, Input\n",
    "from keras_hub.src.models.llama.llama_decoder import LlamaTransformerDecoder\n",
    "from keras_hub.src.models.llama.llama_layernorm import LlamaLayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18607b-2f76-46ab-b443-465dfee810cc",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fafc18e-c6e4-49aa-8aac-4ccfc9cedc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "file_path = \"../DeepInterAware/data/Yeast/Yeast-ProtT5-Full.h5\"\n",
    "\n",
    "loaded_data = {}\n",
    "with h5py.File(file_path, 'r') as hf:\n",
    "    for seq in hf.keys():\n",
    "        loaded_data[seq] = hf[seq][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4023231-5c03-4f31-aa67-504f145b1cab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_A_id</th>\n",
       "      <th>Protein_B_id</th>\n",
       "      <th>Protein_A_sequence</th>\n",
       "      <th>Protein_B_sequence</th>\n",
       "      <th>Protein_A_idx</th>\n",
       "      <th>Protein_B_idx</th>\n",
       "      <th>Interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P16649</td>\n",
       "      <td>P14922</td>\n",
       "      <td>MTASVSNTQNKLNELLDAIRQEFLQVSQEANTYRLQNQKDYDFKMN...</td>\n",
       "      <td>MNPGGEQTIMEQPAQQQQQQQQQQQQQQQQAAVPQQPLDPLTQSTA...</td>\n",
       "      <td>0</td>\n",
       "      <td>577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P07269</td>\n",
       "      <td>P22035</td>\n",
       "      <td>MMEEFSYDHDFNTHFATDLDYLQHDQQQQQQQQHDQQHNQQQQPQP...</td>\n",
       "      <td>MSNISTKDIRKSKPKRGSGFDLLEVTESLGYQTHRKNGRNSWSKDD...</td>\n",
       "      <td>1</td>\n",
       "      <td>1598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P33418</td>\n",
       "      <td>P50278</td>\n",
       "      <td>MLERIQQLVNAVNDPRSDVATKRQAIELLNGIKSSENALEIFISLV...</td>\n",
       "      <td>MTTTVPKVFAFHEFAGVAEAVADHVIHAQNSALKKGKVSRSTQMSG...</td>\n",
       "      <td>2</td>\n",
       "      <td>1599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P27705</td>\n",
       "      <td>P14922</td>\n",
       "      <td>MQSPYPMTQVSNVDDGSLLKESKSKSKVAAKSEAPRPHACPICHRA...</td>\n",
       "      <td>MNPGGEQTIMEQPAQQQQQQQQQQQQQQQQAAVPQQPLDPLTQSTA...</td>\n",
       "      <td>3</td>\n",
       "      <td>577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P05453</td>\n",
       "      <td>P05453</td>\n",
       "      <td>MSDSNQGNNQQNYQQYSQNGNQQQGNNRYQGYQAYNAQAQPAGGYY...</td>\n",
       "      <td>MSDSNQGNNQQNYQQYSQNGNQQQGNNRYQGYQAYNAQAQPAGGYY...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein_A_id Protein_B_id  \\\n",
       "0       P16649       P14922   \n",
       "1       P07269       P22035   \n",
       "2       P33418       P50278   \n",
       "3       P27705       P14922   \n",
       "4       P05453       P05453   \n",
       "\n",
       "                                  Protein_A_sequence  \\\n",
       "0  MTASVSNTQNKLNELLDAIRQEFLQVSQEANTYRLQNQKDYDFKMN...   \n",
       "1  MMEEFSYDHDFNTHFATDLDYLQHDQQQQQQQQHDQQHNQQQQPQP...   \n",
       "2  MLERIQQLVNAVNDPRSDVATKRQAIELLNGIKSSENALEIFISLV...   \n",
       "3  MQSPYPMTQVSNVDDGSLLKESKSKSKVAAKSEAPRPHACPICHRA...   \n",
       "4  MSDSNQGNNQQNYQQYSQNGNQQQGNNRYQGYQAYNAQAQPAGGYY...   \n",
       "\n",
       "                                  Protein_B_sequence  Protein_A_idx  \\\n",
       "0  MNPGGEQTIMEQPAQQQQQQQQQQQQQQQQAAVPQQPLDPLTQSTA...              0   \n",
       "1  MSNISTKDIRKSKPKRGSGFDLLEVTESLGYQTHRKNGRNSWSKDD...              1   \n",
       "2  MTTTVPKVFAFHEFAGVAEAVADHVIHAQNSALKKGKVSRSTQMSG...              2   \n",
       "3  MNPGGEQTIMEQPAQQQQQQQQQQQQQQQQAAVPQQPLDPLTQSTA...              3   \n",
       "4  MSDSNQGNNQQNYQQYSQNGNQQQGNNRYQGYQAYNAQAQPAGGYY...              4   \n",
       "\n",
       "   Protein_B_idx  Interaction  \n",
       "0            577            1  \n",
       "1           1598            1  \n",
       "2           1599            1  \n",
       "3            577            1  \n",
       "4              4            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Fengithub/symLMF-PPI/refs/heads/master/datasets/S.cerevisiae-benchmark/pros_AB.txt\",sep ='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b2de3d-5bf9-4555-9b68-90983a7f28f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4092, 4910)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Protein_A_sequence'].str.len().max(),df['Protein_B_sequence'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cae6a53-8e6e-4f82-96fb-970c6bf9c32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "def process_sequence_tf(x_emb, max_len=512, pad_value=0.0):\n",
    "    seq_len = x_emb.shape[0]\n",
    "    \n",
    "    if seq_len > max_len:\n",
    "        # truncate\n",
    "        x_emb = tf.convert_to_tensor(x_emb[:max_len])\n",
    "        mask = tf.ones([max_len], dtype=tf.float32)\n",
    "    else:\n",
    "        # pad\n",
    "        pad_len = max_len - seq_len\n",
    "        paddings = [[0, pad_len], [0, 0]]\n",
    "        x_emb = tf.pad(x_emb, paddings, constant_values=pad_value)\n",
    "        mask = tf.pad(tf.ones([seq_len], dtype=tf.float32), [[0, pad_len]], constant_values=0.0)\n",
    "    \n",
    "    return x_emb, mask\n",
    "\n",
    "# -----------------------------\n",
    "# Keras Sequence Loader\n",
    "# -----------------------------\n",
    "class DataSequenceLoader(Sequence):\n",
    "    def __init__(self, df, batch_size=32, shuffle=True, max_len=512, pad_value=0.0):\n",
    "        self.x1_emb = df[\"Protein_A_sequence\"].values\n",
    "        self.x2_emb = df[\"Protein_B_sequence\"].values\n",
    "        self.labels = df[\"Interaction\"].values\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.max_len = max_len\n",
    "        self.pad_value = pad_value\n",
    "        self.indices = np.arange(len(df))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "\n",
    "        x1_list, x2_list, m1_list, m2_list = [], [], [], []\n",
    "        labels_list = []\n",
    "\n",
    "        for i in batch_idx:\n",
    "            emb1 = loaded_data[self.x1_emb[i]].reshape(-1, 1024)\n",
    "            emb2 = loaded_data[self.x2_emb[i]].reshape(-1, 1024)\n",
    "\n",
    "            # ---- process embeddings + mask ----\n",
    "            x1_pad, mask1 = process_sequence_tf(emb1, max_len=self.max_len, pad_value=self.pad_value)\n",
    "            x2_pad, mask2 = process_sequence_tf(emb2, max_len=self.max_len, pad_value=self.pad_value)\n",
    "\n",
    "            x1_list.append(x1_pad.numpy())\n",
    "            x2_list.append(x2_pad.numpy())\n",
    "            m1_list.append(mask1.numpy())\n",
    "            m2_list.append(mask2.numpy())\n",
    "            labels_list.append(self.labels[i])\n",
    "\n",
    "        # Convert lists to arrays for batch\n",
    "        x1_batch = np.stack(x1_list, axis=0)\n",
    "        x2_batch = np.stack(x2_list, axis=0)\n",
    "        m1_batch = np.stack(m1_list, axis=0)\n",
    "        m2_batch = np.stack(m2_list, axis=0)\n",
    "        labels_batch = np.array(labels_list)\n",
    "\n",
    "        return (x1_batch, x2_batch, m1_batch, m2_batch), labels_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a643463-b27a-44ba-b50f-6ae7081dd5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loader  = DataSequenceLoader(df,batch_size=4,shuffle =True)\n",
    "# for x in loader:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e053595-ecc9-4960-8d23-7f77235440b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Hybrid Pooling Layer (Max + Avg)\n",
    "# -------------------------------------------------------------------\n",
    "class HybridPooling(layers.Layer):\n",
    "    def call(self, x):\n",
    "        max_pooled = keras.ops.max(x, axis=1)\n",
    "        avg_pooled = keras.ops.mean(x, axis=1)\n",
    "        return keras.ops.concatenate([max_pooled, avg_pooled], axis=-1)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Conv Block (Conv1D → ReLU → Dropout → MaxPool)\n",
    "# -------------------------------------------------------------------\n",
    "def conv_block(x, filters =  100, kernel_sz =20, stride =10, dropout = 0.5):\n",
    "    x = layers.Conv1D(filters, kernel_sz, strides=stride)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=1, padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Cross-attention (Query=X1, Key=X2, Value=X2)\n",
    "# -------------------------------------------------------------------\n",
    "def cross_attention_block(query, key, value, mask, num_heads =4, key_dim =32):\n",
    "    attn = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, \n",
    "        key_dim=key_dim,\n",
    "        dropout=0.0,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        use_bias=True,\n",
    "        # flash_attention=None,  # if GPU supports\n",
    "    )(query, key, value, key_mask=mask, value_mask=mask)\n",
    "    return attn\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# LLaMA Self-Attention Block\n",
    "# -------------------------------------------------------------------\n",
    "def llama_self_attention(x, mask, hidden_dim =100, num_heads = 4):\n",
    "    # single LLaMA decoder layer\n",
    "    llama = LlamaTransformerDecoder(\n",
    "        intermediate_dim=hidden_dim * 4,\n",
    "        # num_heads=num_heads,\n",
    "        num_query_heads=8,\n",
    "        num_key_value_heads=2,\n",
    "        dropout=0.0,\n",
    "        layer_norm_epsilon=1e-5,\n",
    "        activation=\"silu\"\n",
    "    )\n",
    "    return llama(x, decoder_padding_mask=mask)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Functional API Model (PyTorch → Keras Conversion)\n",
    "# -------------------------------------------------------------------\n",
    "def build_model(\n",
    "    input_dim=640,\n",
    "    conv_out=100,\n",
    "    kernel_sz=20,\n",
    "    stride=10,\n",
    "    heads=4,\n",
    "    d_dim=32,\n",
    "    drop_pool=0.5,\n",
    "    drop_linear=0.3\n",
    "):\n",
    "    # Inputs\n",
    "    inp1 = Input((None, 1024))\n",
    "    inp2 = Input((None, 1024))\n",
    "    mask1 = Input((None, ))\n",
    "    mask2 = Input((None, ))\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 1) Convolutional features\n",
    "    # ---------------------------------------------------\n",
    "    # p1 = conv_block(inp1, conv_out, kernel_sz, stride, drop_pool)\n",
    "    # p2 = conv_block(inp2, conv_out, kernel_sz, stride, drop_pool)\n",
    "    x_dim = 384\n",
    "    p1 = layers.Dense(x_dim, use_bias=False,name='stem1')(inp1)\n",
    "    p1 = layers.BatchNormalization(momentum=0.95,name='bn1')(p1)\n",
    "    \n",
    "    p2 = layers.Dense(x_dim, use_bias=False,name='stem2')(inp2)\n",
    "    p2 = layers.BatchNormalization(momentum=0.95,name='bn2')(p2)\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 2) Self Attention using LLaMA blocks\n",
    "    # ---------------------------------------------------\n",
    "    s1 = llama_self_attention(p1, mask1, conv_out, heads)\n",
    "    s2 = llama_self_attention(p2, mask2, conv_out, heads)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 3) Cross Attention (1→2 and 2→1)\n",
    "    # ---------------------------------------------------\n",
    "    c1 = cross_attention_block(p1, p2, p2, mask2, heads, d_dim)\n",
    "    c2 = cross_attention_block(p2, p1, p1, mask1, heads, d_dim)\n",
    "\n",
    "    # Add residual (same as PyTorch + skip)\n",
    "    sc1 = layers.Add()([s1, c1])\n",
    "    sc2 = layers.Add()([s2, c2])\n",
    "\n",
    "    sc1 = layers.Dropout(drop_pool)(sc1)\n",
    "    sc2 = layers.Dropout(drop_pool)(sc2)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 4) Hybrid Pooling (max + mean)\n",
    "    # ---------------------------------------------------\n",
    "    h1 = HybridPooling()(sc1)\n",
    "    h2 = HybridPooling()(sc2)\n",
    "\n",
    "    merged = layers.Concatenate()([h1, h2])\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 5) MLP Head\n",
    "    # ---------------------------------------------------\n",
    "    x = layers.Dense(256, activation=\"relu\")(merged)\n",
    "    x = layers.Dropout(drop_linear)(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(drop_linear)(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs=[inp1, inp2, mask1, mask2], outputs=out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58e6e80-d51c-4bbb-a1eb-500077389c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix\n",
    ")\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b3aa9f-9996-492b-99de-42f44f2cda47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights/Yeast-ProtT5-20260104-064702'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# DEFAULT CONFIG (Logged Automatically to W&B)\n",
    "# =========================================================\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"batch_size\": 4,\n",
    "    \"n_splits\": 5,\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"architecture\": \"ProtT5\",\n",
    "    \"dataset\": \"Yeast\",\n",
    "    \"task\": \"Prot-Prot Classification\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_len\":512,\n",
    "}\n",
    "\n",
    "PROJECT_NAME = f\"{CONFIG['dataset']}-{CONFIG['architecture']}-{TIMESTAMP}\"\n",
    "OUT_PATH = os.path.join(\"weights\",PROJECT_NAME)\n",
    "os.makedirs(os.path.join(OUT_PATH, \"logs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_PATH, \"weights\"), exist_ok=True)\n",
    "OUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b582fad8-ad5f-4541-abf1-1aa553cb293b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      " Fold 1 / 5\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhossainstudy7\u001b[0m (\u001b[33mhossainstudy7-freelancer\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mhossai5/Ag-Ab-Affinity2/Final-Exp-Dec-18-25/wandb/run-20260104_064704-bph9e42e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/bph9e42e' target=\"_blank\">fold_1</a></strong> to <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/bph9e42e' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/bph9e42e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767530826.439754   63792 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79078 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/callbacks/tensorboard.py:680: UserWarning: Model failed to serialize as JSON. Ignoring... 'LlamaTransformerDecoder' object has no attribute 'rope_scaling_factor'\n",
      "  warnings.warn(f\"Model failed to serialize as JSON. Ignoring... {exc}\")\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767530834.268663   64309 service.cc:152] XLA service 0x7ffe4c006e40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1767530834.268703   64309 service.cc:160]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "I0000 00:00:1767530835.311133   64309 cuda_dnn.cc:529] Loaded cuDNN version 90500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/2238\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m170:48:01\u001b[0m 275s/step - accuracy: 0.5000 - auc: 0.6667 - loss: 1.0392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767531103.944725   64309 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.6243 - auc: 0.6662 - loss: 0.8456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 182ms/step - accuracy: 0.7288 - auc: 0.8006 - loss: 0.5844 - val_accuracy: 0.8865 - val_auc: 0.9587 - val_loss: 0.2939\n",
      "Epoch 2/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.8934 - auc: 0.9561 - loss: 0.2672 - val_accuracy: 0.9267 - val_auc: 0.9805 - val_loss: 0.1946\n",
      "Epoch 3/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 20ms/step - accuracy: 0.9317 - auc: 0.9792 - loss: 0.1811 - val_accuracy: 0.9352 - val_auc: 0.9859 - val_loss: 0.1752\n",
      "Epoch 4/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.9512 - auc: 0.9886 - loss: 0.1312 - val_accuracy: 0.9580 - val_auc: 0.9918 - val_loss: 0.1431\n",
      "Epoch 5/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.9592 - auc: 0.9931 - loss: 0.1029 - val_accuracy: 0.9620 - val_auc: 0.9908 - val_loss: 0.1161\n",
      "Epoch 6/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9683 - auc: 0.9941 - loss: 0.0907 - val_accuracy: 0.9522 - val_auc: 0.9923 - val_loss: 0.1345\n",
      "Epoch 7/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 20ms/step - accuracy: 0.9695 - auc: 0.9961 - loss: 0.0766 - val_accuracy: 0.9571 - val_auc: 0.9922 - val_loss: 0.1097\n",
      "Epoch 8/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.9754 - auc: 0.9971 - loss: 0.0632 - val_accuracy: 0.9616 - val_auc: 0.9904 - val_loss: 0.1207\n",
      "Epoch 9/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 20ms/step - accuracy: 0.9775 - auc: 0.9967 - loss: 0.0631 - val_accuracy: 0.9674 - val_auc: 0.9929 - val_loss: 0.0985\n",
      "Epoch 10/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.9778 - auc: 0.9972 - loss: 0.0576 - val_accuracy: 0.9598 - val_auc: 0.9913 - val_loss: 0.1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m556/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step\n",
      "{'fold': 1, 'accuracy': 0.9597855227882037, 'f1': 0.9595687331536388, 'recall': 0.9544235924932976, 'precision': 0.964769647696477, 'roc_auc': 0.9915729686517947, 'aupr': 0.9927496573463946, 'specificity': 0.9651474530831099}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>aupr</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>epoch/auc</td><td>▁▇▇███████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▄▅▇█▇▇▇█▇</td></tr><tr><td>epoch/val_auc</td><td>▁▅▇████▇██</td></tr><tr><td>epoch/val_loss</td><td>█▄▄▃▂▂▁▂▁▁</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95979</td></tr><tr><td>aupr</td><td>0.99275</td></tr><tr><td>epoch/accuracy</td><td>0.97777</td></tr><tr><td>epoch/auc</td><td>0.99724</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>5e-05</td></tr><tr><td>epoch/loss</td><td>0.05763</td></tr><tr><td>epoch/val_accuracy</td><td>0.95979</td></tr><tr><td>epoch/val_auc</td><td>0.99125</td></tr><tr><td>epoch/val_loss</td><td>0.11029</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_1</strong> at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/bph9e42e' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/bph9e42e</a><br> View project at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260104_064704-bph9e42e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      " Fold 2 / 5\n",
      "==========================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mhossai5/Ag-Ab-Affinity2/Final-Exp-Dec-18-25/wandb/run-20260104_070638-qbs04axr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/qbs04axr' target=\"_blank\">fold_2</a></strong> to <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/qbs04axr' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/qbs04axr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/callbacks/tensorboard.py:680: UserWarning: Model failed to serialize as JSON. Ignoring... 'LlamaTransformerDecoder' object has no attribute 'rope_scaling_factor'\n",
      "  warnings.warn(f\"Model failed to serialize as JSON. Ignoring... {exc}\")\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2236/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6152 - auc: 0.6510 - loss: 0.9282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 27ms/step - accuracy: 0.7232 - auc: 0.7902 - loss: 0.6148 - val_accuracy: 0.8852 - val_auc: 0.9548 - val_loss: 0.3133\n",
      "Epoch 2/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8920 - auc: 0.9558 - loss: 0.2677 - val_accuracy: 0.9276 - val_auc: 0.9765 - val_loss: 0.2198\n",
      "Epoch 3/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9326 - auc: 0.9821 - loss: 0.1686 - val_accuracy: 0.9383 - val_auc: 0.9826 - val_loss: 0.1729\n",
      "Epoch 4/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 20ms/step - accuracy: 0.9484 - auc: 0.9885 - loss: 0.1329 - val_accuracy: 0.9383 - val_auc: 0.9842 - val_loss: 0.1689\n",
      "Epoch 5/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9569 - auc: 0.9919 - loss: 0.1102 - val_accuracy: 0.9477 - val_auc: 0.9875 - val_loss: 0.1377\n",
      "Epoch 6/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.9687 - auc: 0.9952 - loss: 0.0840 - val_accuracy: 0.9513 - val_auc: 0.9895 - val_loss: 0.1259\n",
      "Epoch 7/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.9727 - auc: 0.9962 - loss: 0.0739 - val_accuracy: 0.9553 - val_auc: 0.9886 - val_loss: 0.1286\n",
      "Epoch 8/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 19ms/step - accuracy: 0.9740 - auc: 0.9965 - loss: 0.0701 - val_accuracy: 0.9459 - val_auc: 0.9877 - val_loss: 0.1446\n",
      "Epoch 9/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9779 - auc: 0.9975 - loss: 0.0574 - val_accuracy: 0.9468 - val_auc: 0.9879 - val_loss: 0.1393\n",
      "Epoch 10/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 19ms/step - accuracy: 0.9808 - auc: 0.9981 - loss: 0.0510 - val_accuracy: 0.9549 - val_auc: 0.9900 - val_loss: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m558/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step\n",
      "{'fold': 2, 'accuracy': 0.9548704200178731, 'f1': 0.955011135857461, 'recall': 0.9579982126899017, 'precision': 0.9520426287744227, 'roc_auc': 0.9905635137973471, 'aupr': 0.9922743097297222, 'specificity': 0.9517426273458445}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>aupr</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>epoch/auc</td><td>▁▇▇███████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▅▆▆▇██▇▇█</td></tr><tr><td>epoch/val_auc</td><td>▁▅▇▇▇█████</td></tr><tr><td>epoch/val_loss</td><td>█▅▃▃▂▁▁▂▂▁</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95487</td></tr><tr><td>aupr</td><td>0.99227</td></tr><tr><td>epoch/accuracy</td><td>0.98078</td></tr><tr><td>epoch/auc</td><td>0.99815</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>5e-05</td></tr><tr><td>epoch/loss</td><td>0.05099</td></tr><tr><td>epoch/val_accuracy</td><td>0.95487</td></tr><tr><td>epoch/val_auc</td><td>0.99004</td></tr><tr><td>epoch/val_loss</td><td>0.12253</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_2</strong> at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/qbs04axr' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/qbs04axr</a><br> View project at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260104_070638-qbs04axr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      " Fold 3 / 5\n",
      "==========================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mhossai5/Ag-Ab-Affinity2/Final-Exp-Dec-18-25/wandb/run-20260104_071511-p4ljp4ju</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/p4ljp4ju' target=\"_blank\">fold_3</a></strong> to <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/p4ljp4ju' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/p4ljp4ju</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/callbacks/tensorboard.py:680: UserWarning: Model failed to serialize as JSON. Ignoring... 'LlamaTransformerDecoder' object has no attribute 'rope_scaling_factor'\n",
      "  warnings.warn(f\"Model failed to serialize as JSON. Ignoring... {exc}\")\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6281 - auc: 0.6592 - loss: 1.0007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 28ms/step - accuracy: 0.7242 - auc: 0.7839 - loss: 0.6424 - val_accuracy: 0.8601 - val_auc: 0.9539 - val_loss: 0.3312\n",
      "Epoch 2/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.8916 - auc: 0.9543 - loss: 0.2710 - val_accuracy: 0.9209 - val_auc: 0.9776 - val_loss: 0.2102\n",
      "Epoch 3/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.9326 - auc: 0.9799 - loss: 0.1784 - val_accuracy: 0.9428 - val_auc: 0.9877 - val_loss: 0.1535\n",
      "Epoch 4/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.9454 - auc: 0.9880 - loss: 0.1371 - val_accuracy: 0.9187 - val_auc: 0.9854 - val_loss: 0.1949\n",
      "Epoch 5/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.9584 - auc: 0.9925 - loss: 0.1070 - val_accuracy: 0.9486 - val_auc: 0.9903 - val_loss: 0.1353\n",
      "Epoch 6/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.9693 - auc: 0.9952 - loss: 0.0840 - val_accuracy: 0.9307 - val_auc: 0.9879 - val_loss: 0.1800\n",
      "Epoch 7/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 19ms/step - accuracy: 0.9721 - auc: 0.9965 - loss: 0.0717 - val_accuracy: 0.9482 - val_auc: 0.9900 - val_loss: 0.1292\n",
      "Epoch 8/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.9755 - auc: 0.9972 - loss: 0.0626 - val_accuracy: 0.9468 - val_auc: 0.9890 - val_loss: 0.1376\n",
      "Epoch 9/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.9804 - auc: 0.9977 - loss: 0.0539 - val_accuracy: 0.9482 - val_auc: 0.9889 - val_loss: 0.1367\n",
      "Epoch 10/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.9815 - auc: 0.9979 - loss: 0.0485 - val_accuracy: 0.9433 - val_auc: 0.9833 - val_loss: 0.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m558/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step\n",
      "{'fold': 3, 'accuracy': 0.9432529043789097, 'f1': 0.9415016121602948, 'recall': 0.9133154602323503, 'precision': 0.9714828897338403, 'roc_auc': 0.9859842304623767, 'aupr': 0.9880279273420506, 'specificity': 0.9731903485254692}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>aupr</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>epoch/auc</td><td>▁▇▇███████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▆█▆█▇████</td></tr><tr><td>epoch/val_auc</td><td>▁▆█▇█████▇</td></tr><tr><td>epoch/val_loss</td><td>█▄▂▃▁▃▁▁▁▃</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94325</td></tr><tr><td>aupr</td><td>0.98803</td></tr><tr><td>epoch/accuracy</td><td>0.98145</td></tr><tr><td>epoch/auc</td><td>0.99795</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>5e-05</td></tr><tr><td>epoch/loss</td><td>0.04851</td></tr><tr><td>epoch/val_accuracy</td><td>0.94325</td></tr><tr><td>epoch/val_auc</td><td>0.98328</td></tr><tr><td>epoch/val_loss</td><td>0.17404</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_3</strong> at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/p4ljp4ju' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/p4ljp4ju</a><br> View project at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260104_071511-p4ljp4ju/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      " Fold 4 / 5\n",
      "==========================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mhossai5/Ag-Ab-Affinity2/Final-Exp-Dec-18-25/wandb/run-20260104_072306-67dkhow8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/67dkhow8' target=\"_blank\">fold_4</a></strong> to <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/67dkhow8' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/67dkhow8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/callbacks/tensorboard.py:680: UserWarning: Model failed to serialize as JSON. Ignoring... 'LlamaTransformerDecoder' object has no attribute 'rope_scaling_factor'\n",
      "  warnings.warn(f\"Model failed to serialize as JSON. Ignoring... {exc}\")\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6233 - auc: 0.6640 - loss: 0.9032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 193ms/step - accuracy: 0.7248 - auc: 0.7976 - loss: 0.5952 - val_accuracy: 0.8932 - val_auc: 0.9572 - val_loss: 0.2907\n",
      "Epoch 2/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.8948 - auc: 0.9576 - loss: 0.2610 - val_accuracy: 0.8713 - val_auc: 0.9829 - val_loss: 0.2737\n",
      "Epoch 3/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9350 - auc: 0.9821 - loss: 0.1690 - val_accuracy: 0.9383 - val_auc: 0.9846 - val_loss: 0.1608\n",
      "Epoch 4/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9527 - auc: 0.9886 - loss: 0.1309 - val_accuracy: 0.9410 - val_auc: 0.9820 - val_loss: 0.1861\n",
      "Epoch 5/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.9584 - auc: 0.9916 - loss: 0.1118 - val_accuracy: 0.9535 - val_auc: 0.9896 - val_loss: 0.1350\n",
      "Epoch 6/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.9682 - auc: 0.9950 - loss: 0.0827 - val_accuracy: 0.9477 - val_auc: 0.9892 - val_loss: 0.1322\n",
      "Epoch 7/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9735 - auc: 0.9955 - loss: 0.0772 - val_accuracy: 0.9464 - val_auc: 0.9852 - val_loss: 0.1557\n",
      "Epoch 8/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.9799 - auc: 0.9969 - loss: 0.0586 - val_accuracy: 0.9526 - val_auc: 0.9900 - val_loss: 0.1202\n",
      "Epoch 9/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9773 - auc: 0.9974 - loss: 0.0599 - val_accuracy: 0.9611 - val_auc: 0.9904 - val_loss: 0.1123\n",
      "Epoch 10/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.9782 - auc: 0.9968 - loss: 0.0622 - val_accuracy: 0.9575 - val_auc: 0.9922 - val_loss: 0.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m556/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step\n",
      "{'fold': 4, 'accuracy': 0.957532409476978, 'f1': 0.957149300857014, 'recall': 0.9481680071492404, 'precision': 0.9663023679417122, 'roc_auc': 0.9921609346448801, 'aupr': 0.9932681013860887, 'specificity': 0.9669051878354203}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>aupr</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>epoch/auc</td><td>▁▇▇███████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▃▁▆▆▇▇▇▇██</td></tr><tr><td>epoch/val_auc</td><td>▁▆▆▆▇▇▇███</td></tr><tr><td>epoch/val_loss</td><td>█▇▃▄▂▂▃▁▁▁</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95753</td></tr><tr><td>aupr</td><td>0.99327</td></tr><tr><td>epoch/accuracy</td><td>0.97821</td></tr><tr><td>epoch/auc</td><td>0.99676</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>5e-05</td></tr><tr><td>epoch/loss</td><td>0.06218</td></tr><tr><td>epoch/val_accuracy</td><td>0.95753</td></tr><tr><td>epoch/val_auc</td><td>0.99218</td></tr><tr><td>epoch/val_loss</td><td>0.10852</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_4</strong> at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/67dkhow8' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/67dkhow8</a><br> View project at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260104_072306-67dkhow8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      " Fold 5 / 5\n",
      "==========================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mhossai5/Ag-Ab-Affinity2/Final-Exp-Dec-18-25/wandb/run-20260104_073746-weg6ql63</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/weg6ql63' target=\"_blank\">fold_5</a></strong> to <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/weg6ql63' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/weg6ql63</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/callbacks/tensorboard.py:680: UserWarning: Model failed to serialize as JSON. Ignoring... 'LlamaTransformerDecoder' object has no attribute 'rope_scaling_factor'\n",
      "  warnings.warn(f\"Model failed to serialize as JSON. Ignoring... {exc}\")\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2236/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6179 - auc: 0.6486 - loss: 1.0247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 27ms/step - accuracy: 0.7203 - auc: 0.7786 - loss: 0.6481 - val_accuracy: 0.8789 - val_auc: 0.9464 - val_loss: 0.3185\n",
      "Epoch 2/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 20ms/step - accuracy: 0.8877 - auc: 0.9540 - loss: 0.2744 - val_accuracy: 0.9133 - val_auc: 0.9802 - val_loss: 0.2295\n",
      "Epoch 3/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.9275 - auc: 0.9796 - loss: 0.1815 - val_accuracy: 0.9428 - val_auc: 0.9833 - val_loss: 0.1657\n",
      "Epoch 4/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.9517 - auc: 0.9891 - loss: 0.1287 - val_accuracy: 0.9477 - val_auc: 0.9864 - val_loss: 0.1502\n",
      "Epoch 5/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.9590 - auc: 0.9918 - loss: 0.1094 - val_accuracy: 0.9437 - val_auc: 0.9897 - val_loss: 0.1455\n",
      "Epoch 6/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.9680 - auc: 0.9939 - loss: 0.0887 - val_accuracy: 0.9338 - val_auc: 0.9895 - val_loss: 0.1573\n",
      "Epoch 7/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.9711 - auc: 0.9959 - loss: 0.0754 - val_accuracy: 0.9571 - val_auc: 0.9907 - val_loss: 0.1192\n",
      "Epoch 8/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.9751 - auc: 0.9965 - loss: 0.0672 - val_accuracy: 0.9446 - val_auc: 0.9901 - val_loss: 0.1450\n",
      "Epoch 9/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 19ms/step - accuracy: 0.9762 - auc: 0.9971 - loss: 0.0620 - val_accuracy: 0.9531 - val_auc: 0.9909 - val_loss: 0.1169\n",
      "Epoch 10/10\n",
      "\u001b[1m2238/2238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.9825 - auc: 0.9983 - loss: 0.0463 - val_accuracy: 0.9517 - val_auc: 0.9892 - val_loss: 0.1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m556/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step\n",
      "{'fold': 5, 'accuracy': 0.951721054984354, 'f1': 0.9505041246562786, 'recall': 0.9275491949910555, 'precision': 0.974624060150376, 'roc_auc': 0.9902673131677433, 'aupr': 0.9916782160780181, 'specificity': 0.9758713136729222}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>aupr</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▅▇▇▇█████</td></tr><tr><td>epoch/auc</td><td>▁▇▇███████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▄▇▇▇▆█▇██</td></tr><tr><td>epoch/val_auc</td><td>▁▆▇▇██████</td></tr><tr><td>epoch/val_loss</td><td>█▅▃▂▂▂▁▂▁▁</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95172</td></tr><tr><td>aupr</td><td>0.99168</td></tr><tr><td>epoch/accuracy</td><td>0.98246</td></tr><tr><td>epoch/auc</td><td>0.99828</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>5e-05</td></tr><tr><td>epoch/loss</td><td>0.04626</td></tr><tr><td>epoch/val_accuracy</td><td>0.95172</td></tr><tr><td>epoch/val_auc</td><td>0.98924</td></tr><tr><td>epoch/val_loss</td><td>0.12901</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_5</strong> at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/weg6ql63' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702/runs/weg6ql63</a><br> View project at: <a href='https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702' target=\"_blank\">https://wandb.ai/hossainstudy7-freelancer/Yeast-ProtT5-20260104-064702</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260104_073746-weg6ql63/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All fold metrics saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_63792/2094829001.py:138: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Average' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  metrics_df.loc[metrics_df.index[-1], \"fold\"] = \"Average\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>aupr</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959786</td>\n",
       "      <td>0.959569</td>\n",
       "      <td>0.954424</td>\n",
       "      <td>0.964770</td>\n",
       "      <td>0.991573</td>\n",
       "      <td>0.992750</td>\n",
       "      <td>0.965147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.954870</td>\n",
       "      <td>0.955011</td>\n",
       "      <td>0.957998</td>\n",
       "      <td>0.952043</td>\n",
       "      <td>0.990564</td>\n",
       "      <td>0.992274</td>\n",
       "      <td>0.951743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.943253</td>\n",
       "      <td>0.941502</td>\n",
       "      <td>0.913315</td>\n",
       "      <td>0.971483</td>\n",
       "      <td>0.985984</td>\n",
       "      <td>0.988028</td>\n",
       "      <td>0.973190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.957532</td>\n",
       "      <td>0.957149</td>\n",
       "      <td>0.948168</td>\n",
       "      <td>0.966302</td>\n",
       "      <td>0.992161</td>\n",
       "      <td>0.993268</td>\n",
       "      <td>0.966905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.951721</td>\n",
       "      <td>0.950504</td>\n",
       "      <td>0.927549</td>\n",
       "      <td>0.974624</td>\n",
       "      <td>0.990267</td>\n",
       "      <td>0.991678</td>\n",
       "      <td>0.975871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average</td>\n",
       "      <td>0.953432</td>\n",
       "      <td>0.952747</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.965844</td>\n",
       "      <td>0.990110</td>\n",
       "      <td>0.991600</td>\n",
       "      <td>0.966571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fold  accuracy        f1    recall  precision   roc_auc      aupr  \\\n",
       "0      1.0  0.959786  0.959569  0.954424   0.964770  0.991573  0.992750   \n",
       "1      2.0  0.954870  0.955011  0.957998   0.952043  0.990564  0.992274   \n",
       "2      3.0  0.943253  0.941502  0.913315   0.971483  0.985984  0.988028   \n",
       "3      4.0  0.957532  0.957149  0.948168   0.966302  0.992161  0.993268   \n",
       "4      5.0  0.951721  0.950504  0.927549   0.974624  0.990267  0.991678   \n",
       "5  Average  0.953432  0.952747  0.940291   0.965844  0.990110  0.991600   \n",
       "\n",
       "   specificity  \n",
       "0     0.965147  \n",
       "1     0.951743  \n",
       "2     0.973190  \n",
       "3     0.966905  \n",
       "4     0.975871  \n",
       "5     0.966571  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score,\n",
    "    roc_auc_score, matthews_corrcoef, confusion_matrix,\n",
    "    average_precision_score\n",
    ")\n",
    "CONFIG['n_splits'] =5\n",
    "# =============================================================\n",
    "#  K-FOLD CROSS VALIDATION SETTINGS\n",
    "# =============================================================\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_splits'], shuffle=True, random_state=42)\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "# =============================================================\n",
    "#  MAIN LOOP\n",
    "# =============================================================\n",
    "for fold,(train_idx, valid_idx) in enumerate(skf.split(df, df[\"Interaction\"]),1):\n",
    "    print(f\"\\n==========================\")\n",
    "    print(f\" Fold {fold} / {CONFIG['n_splits']}\")\n",
    "    print(f\"==========================\")\n",
    "    run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            name=f\"fold_{fold}\",\n",
    "            group=\"KFold-CV\",\n",
    "            config={**CONFIG, \"fold\": fold},\n",
    "            reinit=True\n",
    "        )\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    valid_df = df.iloc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Loaders\n",
    "    # ---------------------------------------\n",
    "    train_loader = DataSequenceLoader(\n",
    "        train_df, \n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        max_len = CONFIG['max_len'], \n",
    "        shuffle=True)\n",
    "    valid_loader = DataSequenceLoader(\n",
    "        valid_df, \n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        max_len = CONFIG['max_len'], \n",
    "        shuffle=False)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Build a FRESH MODEL per fold\n",
    "    # ---------------------------------------\n",
    "    model = build_model()\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(CONFIG[\"learning_rate\"]),\n",
    "        loss=CONFIG[\"loss\"],\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            tf.keras.metrics.AUC(name=\"auc\")\n",
    "        ]\n",
    "    )\n",
    "    # -----------------------------------------------------\n",
    "    # Callbacks\n",
    "    # -----------------------------------------------------\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(OUT_PATH, \"logs\", f\"fold_{fold}\")\n",
    "    )\n",
    "\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\n",
    "            OUT_PATH, \"weights\",\n",
    "            f\"weights_fold{fold}-best.weights.h5\"\n",
    "        ),\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "    # ---------------------------------------\n",
    "    # Train\n",
    "    # ---------------------------------------\n",
    "    history = model.fit(\n",
    "        train_loader,\n",
    "        validation_data=valid_loader,\n",
    "        epochs=CONFIG[\"epochs\"],\n",
    "        callbacks=[\n",
    "            tb_callback,\n",
    "            checkpoint_cb,\n",
    "            WandbMetricsLogger(log_freq=\"epoch\")\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.save_weights(\n",
    "        os.path.join(\n",
    "            OUT_PATH,\n",
    "            \"weights\",\n",
    "            f\"weights_fold{fold}-last.weights.h5\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Evaluation\n",
    "    # -----------------------------------------------------\n",
    "    y_pred_prob = model.predict(valid_loader).ravel()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    y_true = valid_df[\"Interaction\"].values\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"fold\": fold,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_pred_prob),\n",
    "        \"aupr\": average_precision_score(y_true, y_pred_prob),\n",
    "        \"specificity\": specificity\n",
    "    }\n",
    "\n",
    "    # Log fold metrics to W&B\n",
    "    wandb.log(metrics_dict)\n",
    "\n",
    "    print(metrics_dict)\n",
    "    all_metrics.append(metrics_dict)\n",
    "\n",
    "    run.finish()\n",
    "\n",
    "# =========================================================\n",
    "# Save All Metrics\n",
    "# =========================================================\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "avg_row = metrics_df.mean(numeric_only=True)\n",
    "metrics_df = pd.concat(\n",
    "    [metrics_df, avg_row.to_frame().T],\n",
    "    ignore_index=True\n",
    ")\n",
    "metrics_df.loc[metrics_df.index[-1], \"fold\"] = \"Average\"\n",
    "\n",
    "metrics_df.to_csv(\n",
    "    os.path.join(\n",
    "        OUT_PATH,\n",
    "        f\"{PROJECT_NAME}-kfold_classification_metrics.csv\"\n",
    "    ),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nAll fold metrics saved.\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf6e1f2-89a8-4ab3-af9c-5317a07729c0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m556/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step\n",
      "{'fold': 1, 'accuracy': 0.9673815907059875, 'f1': 0.9669234254644313, 'recall': 0.9535299374441466, 'precision': 0.9806985294117647, 'mcc': 0.9351220908566883, 'auc': 0.9929841290377196, 'prauc': 0.9940483459145044, 'specificity': 0.9812332439678284, 'sensitivity': 0.9535299374441466}\n",
      "\n",
      "Evaluating Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m556/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step\n",
      "{'fold': 2, 'accuracy': 0.9548704200178731, 'f1': 0.955011135857461, 'recall': 0.9579982126899017, 'precision': 0.9520426287744227, 'mcc': 0.909758640705754, 'auc': 0.9905635137973471, 'prauc': 0.9922743097297222, 'specificity': 0.9517426273458445, 'sensitivity': 0.9579982126899017}\n",
      "\n",
      "Evaluating Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m558/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step\n",
      "{'fold': 3, 'accuracy': 0.9481680071492404, 'f1': 0.9467889908256881, 'recall': 0.9222520107238605, 'precision': 0.9726672950047125, 'mcc': 0.8975424739759503, 'auc': 0.9897481234441896, 'prauc': 0.9912045097618505, 'specificity': 0.9740840035746202, 'sensitivity': 0.9222520107238605}\n",
      "\n",
      "Evaluating Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m555/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step\n",
      "{'fold': 4, 'accuracy': 0.957532409476978, 'f1': 0.957149300857014, 'recall': 0.9481680071492404, 'precision': 0.9663023679417122, 'mcc': 0.9152268379237681, 'auc': 0.9921609346448801, 'prauc': 0.9932681013860887, 'specificity': 0.9669051878354203, 'sensitivity': 0.9481680071492404}\n",
      "\n",
      "Evaluating Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/antibody_dl/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m556/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are explicitly setting `padding_mask` while the `inputs` have built-in mask, so the built-in mask is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step\n",
      "{'fold': 5, 'accuracy': 0.9530621367903442, 'f1': 0.9533540648600622, 'recall': 0.9597495527728086, 'precision': 0.9470432480141218, 'mcc': 0.9062063109440174, 'auc': 0.9914455310053539, 'prauc': 0.9926356483461605, 'specificity': 0.9463806970509383, 'sensitivity': 0.9597495527728086}\n",
      "\n",
      "Evaluation completed and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_63792/1787549430.py:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Average' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  avg_row[\"fold\"] = \"Average\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>mcc</th>\n",
       "      <th>auc</th>\n",
       "      <th>prauc</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.967382</td>\n",
       "      <td>0.966923</td>\n",
       "      <td>0.95353</td>\n",
       "      <td>0.980699</td>\n",
       "      <td>0.935122</td>\n",
       "      <td>0.992984</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.95353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.95487</td>\n",
       "      <td>0.955011</td>\n",
       "      <td>0.957998</td>\n",
       "      <td>0.952043</td>\n",
       "      <td>0.909759</td>\n",
       "      <td>0.990564</td>\n",
       "      <td>0.992274</td>\n",
       "      <td>0.951743</td>\n",
       "      <td>0.957998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.948168</td>\n",
       "      <td>0.946789</td>\n",
       "      <td>0.922252</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.897542</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.991205</td>\n",
       "      <td>0.974084</td>\n",
       "      <td>0.922252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.957532</td>\n",
       "      <td>0.957149</td>\n",
       "      <td>0.948168</td>\n",
       "      <td>0.966302</td>\n",
       "      <td>0.915227</td>\n",
       "      <td>0.992161</td>\n",
       "      <td>0.993268</td>\n",
       "      <td>0.966905</td>\n",
       "      <td>0.948168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>0.953354</td>\n",
       "      <td>0.95975</td>\n",
       "      <td>0.947043</td>\n",
       "      <td>0.906206</td>\n",
       "      <td>0.991446</td>\n",
       "      <td>0.992636</td>\n",
       "      <td>0.946381</td>\n",
       "      <td>0.95975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average</td>\n",
       "      <td>0.956203</td>\n",
       "      <td>0.955845</td>\n",
       "      <td>0.94834</td>\n",
       "      <td>0.963751</td>\n",
       "      <td>0.912771</td>\n",
       "      <td>0.99138</td>\n",
       "      <td>0.992686</td>\n",
       "      <td>0.964069</td>\n",
       "      <td>0.94834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fold  accuracy        f1    recall precision       mcc       auc  \\\n",
       "0        1  0.967382  0.966923   0.95353  0.980699  0.935122  0.992984   \n",
       "1        2   0.95487  0.955011  0.957998  0.952043  0.909759  0.990564   \n",
       "2        3  0.948168  0.946789  0.922252  0.972667  0.897542  0.989748   \n",
       "3        4  0.957532  0.957149  0.948168  0.966302  0.915227  0.992161   \n",
       "4        5  0.953062  0.953354   0.95975  0.947043  0.906206  0.991446   \n",
       "5  Average  0.956203  0.955845   0.94834  0.963751  0.912771   0.99138   \n",
       "\n",
       "      prauc specificity sensitivity  \n",
       "0  0.994048    0.981233     0.95353  \n",
       "1  0.992274    0.951743    0.957998  \n",
       "2  0.991205    0.974084    0.922252  \n",
       "3  0.993268    0.966905    0.948168  \n",
       "4  0.992636    0.946381     0.95975  \n",
       "5  0.992686    0.964069     0.94834  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================\n",
    "#  EVALUATION (POST-TRAINING)\n",
    "# =============================================================\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score,\n",
    "    roc_auc_score, matthews_corrcoef,\n",
    "    confusion_matrix, average_precision_score\n",
    ")\n",
    "\n",
    "all_metrics = []\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_splits'], shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (_, valid_idx) in enumerate(\n",
    "        skf.split(df, df[\"Interaction\"]), 1):\n",
    "\n",
    "    print(f\"\\nEvaluating Fold {fold}\")\n",
    "\n",
    "    valid_df = df.iloc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "    valid_loader = DataSequenceLoader(\n",
    "        valid_df,\n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        max_len=CONFIG[\"max_len\"],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Rebuild model & load best weights\n",
    "    model = build_model()\n",
    "    model.load_weights(\n",
    "        os.path.join(\n",
    "            OUT_PATH, \"weights\",\n",
    "            f\"weights_fold{fold}-best.weights.h5\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Prediction\n",
    "    y_prob = model.predict(valid_loader).ravel()\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    y_true = valid_df[\"Interaction\"].values\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"fold\": fold,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),     # sensitivity\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"mcc\": matthews_corrcoef(y_true, y_pred),\n",
    "        \"auc\": roc_auc_score(y_true, y_prob),\n",
    "        \"prauc\": average_precision_score(y_true, y_prob),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0.0,\n",
    "        \"sensitivity\": tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    }\n",
    "\n",
    "    print(metrics_dict)\n",
    "    all_metrics.append(metrics_dict)\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "avg_row = metrics_df.mean(numeric_only=True)\n",
    "avg_row[\"fold\"] = \"Average\"\n",
    "\n",
    "metrics_df = pd.concat(\n",
    "    [metrics_df, avg_row.to_frame().T],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "metrics_df.to_csv(\n",
    "    os.path.join(\n",
    "        OUT_PATH,\n",
    "        f\"{PROJECT_NAME}-kfold_evaluation_metrics.csv\"\n",
    "    ),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation completed and saved.\")\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d23ec6-3cef-45ae-800e-3e43864cba03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-antibody_dl]",
   "language": "python",
   "name": "conda-env-.conda-antibody_dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
