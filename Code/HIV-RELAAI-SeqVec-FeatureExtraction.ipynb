{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abadbb66-813d-427e-b1fd-7e7d2f8273ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossai5/.conda/envs/bio-emb/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-18 18:11:57.596336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-18 18:12:15.008973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer, \n",
    "    T5EncoderModel, \n",
    "    EsmModel, \n",
    "    EsmTokenizer,\n",
    ")\n",
    "# import ablang2\n",
    "from bio_embeddings.embed import ProtTransBertBFDEmbedder,SeqVecEmbedder\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1608ba6e-10fd-4b4d-8592-546308254f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Using device: cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DEVICE SETUP\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n[INFO] Using device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0356994-f2f4-4ebc-aa5f-caa284dcd71b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB-Bind  AVIDa_hIL6  BioMap  CoVAbDab  example\tHIV  SAbDab  SabDab2  Yeast\n"
     ]
    }
   ],
   "source": [
    "!ls ../DeepInterAware/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79401dcd-404c-4c56-aa65-1176d7aa7caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "ab_df   = pd.read_csv(\"../DeepInterAware/data/SAbDab/antibody.csv\")\n",
    "ag_df   = pd.read_csv(\"../DeepInterAware/data/SAbDab/antigen.csv\")\n",
    "\n",
    "# Unique sequences\n",
    "seq_list = pd.unique(\n",
    "    pd.concat([ab_df[\"ab_seq\"],ag_df[\"ag_seq\"]],axis =0).values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b780aed0-9a30-47a7-bb27-5858e7148191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DVQMTQSPSYLAASPGESVSISCKATENINTYLAWYQAKPGKTTKLLLYSGSTLQSGTPSRFSGSGSGTDFTLTISSLEPEDFAVYYCQQHNEYPLTFGSGTKLEIKEVELVESGGDLVQPGRSLKLSCAASGFTFSNLAMAWVRQTPTKGLEWVASISPAGITTYYRDSVKGRFTISRDNARNTQYLQMDSLRSEDTATYYCARHTGKSSFDYWGQGVMVTVSSG',\n",
       "       'DIVITQSPSSMYASLGERVTITCKASQDINSYLSWFQQKPGKSPKTLIYRANRLVDGVPSRFSGSGSGQDYSLTISSLEYEDMGIYYCLQYDEFPLTFGAGTKLELKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGECEVQLQESGPELVKPGASVKIPCKASGYTFTDYNMDWVKQSHGKSLEWIGDINPNNGGTIYNQKFKGKATLTVDKSSSTAYMELRSLTSEDTAVYYCARPDYYGSYGWYFDVWGTGTTVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKS',\n",
       "       'DIQMTQSPASLSVSVGETVTITCRASENIYSNLIWYQQKQGKSPQLLVYAATNLADGVPSRFSGSGSGTQYSLKINSLQSEDFGSYYCQHFWGTPLTFGAGTKLEIKRADAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRNECQVQLLQSGAELVRPGSSVKISCKASGYVFTSYWMHWVKQRPGQGLEWIGQIYPGDGGTHYNGNFRDKATLTADKSSSTAYMHLSLTSEDSAVYFCARKIYDGYGFSYWGQGTLVTVSAKTTPPSVYPLAPGSAAQTNSMVTLGCLVKGYFPEPVTVTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVPSSPRPSETVTCNVAHPASSTKVDKKI'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284bfe52-cf31-472d-9b4d-f7eef268fb60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOAD ABLANG2 (ANTIBODY MODEL)\n",
    "# ============================================================\n",
    "def load_ablang2():\n",
    "    model_name = \"ablang2-paired\"\n",
    "    print(f\"[INFO] Loading AbLang2: {model_name}\")\n",
    "\n",
    "    model = ablang2.pretrained(\n",
    "        model_to_use=model_name,\n",
    "        random_init=False,\n",
    "        device=device\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# LOAD ProtT5 (ANTIGEN MODEL)\n",
    "# ============================================================\n",
    "def load_prott5():\n",
    "    model_name = \"Rostlab/prot_t5_xl_half_uniref50-enc\"\n",
    "    print(f\"[INFO] Loading ProtT5: {model_name}\")\n",
    "\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        do_lower_case=False\n",
    "    )\n",
    "    model = T5EncoderModel.from_pretrained(model_name)\n",
    "\n",
    "    model = model.half() if device.type == \"cuda\" else model.float()\n",
    "    model = model.to(device).eval()\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "# ============================================================\n",
    "# LOAD ESM2 (Antigen Model)\n",
    "# ============================================================\n",
    "def load_esm2():\n",
    "    model_name = \"facebook/esm2_t36_3B_UR50D\"\n",
    "    print(f\"[INFO] Loading ESM2 model: {model_name}\")\n",
    "\n",
    "    tokenizer = EsmTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        do_lower_case=False\n",
    "    )\n",
    "    model = EsmModel.from_pretrained(model_name)\n",
    "\n",
    "    # FP16 for GPU, FP32 for CPU\n",
    "    if device.type == \"cuda\":\n",
    "        model = model.half()\n",
    "    else:\n",
    "        model = model.float()\n",
    "\n",
    "    model = model.to(device).eval()\n",
    "    return model, tokenizer\n",
    "\n",
    "# ============================================================\n",
    "# EMBEDDING FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def embed_ablang(hseq: str, lseq: str):\n",
    "    \"\"\"\n",
    "    AbLang2 antibody embedding (VH | VL)\n",
    "    Output shape: (L, D)\n",
    "    \"\"\"\n",
    "    seq = f\"{hseq}|{lseq}\".upper()\n",
    "\n",
    "    tokens = ab_model.tokenizer(\n",
    "        [seq],\n",
    "        pad=True,\n",
    "        w_extra_tkns=False,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = ab_model.AbRep(tokens).last_hidden_states\n",
    "\n",
    "    return output.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "def embed_prot(seq: str):\n",
    "    \"\"\"\n",
    "    ProtT5 antigen embedding\n",
    "    Output shape: (L, 1024)\n",
    "    \"\"\"\n",
    "    seq = re.sub(r\"[UZOB]\", \"X\", seq)\n",
    "    seq = \" \".join(seq)\n",
    "\n",
    "    inputs = ag_tokenizer(\n",
    "        seq,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = ag_model(**inputs)\n",
    "\n",
    "    token_emb = outputs.last_hidden_state.squeeze(0)\n",
    "    mask = inputs[\"attention_mask\"].squeeze(0).bool()\n",
    "\n",
    "    return token_emb[mask].cpu().numpy()\n",
    "\n",
    "def embed_esm(seq: str):\n",
    "    \"\"\"\n",
    "    Returns ESM2 embeddings for antigen. shape 2560\n",
    "    \"\"\"\n",
    "    tokens = esm_tokenizer(\n",
    "        seq,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "\n",
    "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = esm_model(**tokens)\n",
    "\n",
    "    return output.last_hidden_state.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fddeb24-4d26-4571-a5d7-2bab111b431d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ag_model, ag_tokenizer = load_prott5()\n",
    "# ab_model = load_ablang2()\n",
    "# esm_model, esm_tokenizer = load_esm2()\n",
    "seqvec_emb = SeqVecEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a00bfb-0d1d-4bde-a14a-d93b4935e98b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving embeddings to:\n",
      "./data/SabDab/SabDab_SeqVec_Full.h5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2722/2722 [40:28<00:00,  1.12it/s]  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SAVE EMBEDDINGS (HDF5)\n",
    "# ============================================================\n",
    "\n",
    "OUTPUT_PATH = \"./data/SabDab/SabDab_SeqVec_Full.h5\"\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH),exist_ok =True)\n",
    "print(f\"[INFO] Saving embeddings to:\\n{OUTPUT_PATH}\\n\")\n",
    "\n",
    "with h5py.File(OUTPUT_PATH, \"w\") as hf:\n",
    "    for seq in tqdm(seq_list):\n",
    "        emb = seqvec_emb.embed(seq).reshape(-1).tolist()\n",
    "        hf.create_dataset(seq, data=emb, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4cf198-2062-4173-af4a-228d96e7e468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding shape: (3, 226, 1024)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SANITY CHECK\n",
    "# ============================================================\n",
    "\n",
    "print(\"Sample embedding shape:\",\n",
    "      seqvec_emb.embed(seq_list[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f187319a-64ce-4d5a-80b1-c98ac795b18e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2aca6bc8e049799418d88bf486ea9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2722 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_seq ={}\n",
    "\n",
    "with h5py.File(OUTPUT_PATH, \"r\") as hf:\n",
    "    for seq in tqdm(hf.keys()):\n",
    "        load_seq[seq] =hf[seq][:]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260b3ea7-f842-43cf-a5ed-761be1f4198c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAALTQPLSVSVSPGQTAIFTCSGDNLGDKYVYWFQQRPGQSPALLIYQDNKRPSGIPERFSGSNSGNTATLTISGTQSTDEADYYCQTWDSTVVFGGGTKLQVQLQESGPGLVAASDTLSLTCTVSGGSLAAFYWSWIRQAPGKGLEWIGYIYYSGSAYYSPSLESRVTMSDAAAAAAAAAAAAAVYYCVRAAAAAAFASWGQGTLVTV': array([ 0.01722717, -0.01322937, -0.05004883, ...,  0.06414795,\n",
       "        -0.12078857, -0.19470215])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae43be-0900-47cd-b149-7b7d0754a033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load_seq['DIVITQSPSSMYASLGERVTITCKASQDINSYLSWFQQKPGKSPKTLIYRANRLVDGVPSRFSGSGSGQDYSLTISSLEYEDMGIYYCLQYDEFPLTFGAGTKLELKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGECEVQLQESGPELVKPGASVKIPCKASGYTFTDYNMDWVKQSHGKSLEWIGDINPNNGGTIYNQKFKGKATLTVDKSSSTAYMELRSLTSEDTAVYYCARPDYYGSYGWYFDVWGTGTTVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKS']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bio-emb]",
   "language": "python",
   "name": "conda-env-.conda-bio-emb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
